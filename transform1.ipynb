{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pd.ExcelFile(f'/workspaces/vikrant_dubai/RAW/AD/AD {k}.xlsx')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Station Name\", \"Latitude\", \"Longitude\", \"Region\", \"Area Classification\"])\n",
    "dfs = []\n",
    "for i in range(len(excel_file.sheet_names)-4):\n",
    "    df = pd.read_excel(f\"/workspaces/vikrant_dubai/RAW/AD/AD {k}.xlsx\", sheet_name = excel_file.sheet_names[i])\n",
    "    df2 = df.iloc[:, :8]\n",
    "\n",
    "    df = df2.transpose().iloc[:, :1]\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "\n",
    "    mapped_data = {\n",
    "        \"Station Name\": df.index[0],  \n",
    "        \"Latitude\": df.iloc[1, 0],  \n",
    "        \"Longitude\": df.iloc[3, 0],  \n",
    "        \"Region\": df.index[3],  \n",
    "        \"Area Classification\": df.index[6]  \n",
    "    }\n",
    "    temp_df = pd.DataFrame([mapped_data])\n",
    "    dfs.append(temp_df)\n",
    "\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "final_df.to_csv(f'/workspaces/vikrant_dubai/final/details{k}.csv', index=False)\n",
    "\n",
    "\n",
    "L2=[   'Date/Time', 'SO2', 'DATA CAP. (SO2)', 'SO2 Avg', 'NO2', 'DATA CAP. (NO2)', 'NO2 Avg',     'O3', 'DATA CAP. (O3)', 'O3 8H Avg.', 'Daily Capture', 'O3 Daily Average', 'O3 Daily Average (NS)', 'CO',     'DATA CAP. (CO)', 'CO 8H Avg.', 'Daily Capture', 'CO Daily Average', 'PM10',     'DATA CAP. (PM10)', 'PM10 Avg', 'PM2.5', 'DATA CAP. (PM2.5)', 'PM2.5 Avg',     'Lower Ambient Temperature', 'Upper Ambient Temperature', 'Barometric Pressure',    'Relative Humidity', 'Wind Direction', 'Wind Speed', 'H2S', 'Toluene', 'O_Xylene',     'Ethylbenzene', 'mp_xylene_', 'Benzene', 'CH4', 'NMHC', 'THC', 'Noise' ]\n",
    "\n",
    "L2 = [elem.upper() for elem in L2]\n",
    "\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for sheet_index in range(len(excel_file.sheet_names)-4):\n",
    "    df3=pd.read_excel(\"/workspaces/vikrant_dubai/RAW/AD/AD 1.xlsx\", sheet_name = excel_file.sheet_names[sheet_index])\n",
    "    new_df_columns = df3.iloc[4]\n",
    "\n",
    "    # Iterate over the series and replace the column names\n",
    "    for col_index in range(1, len(new_df_columns)):\n",
    "        if 'DATA CAP.' in new_df_columns[col_index]:\n",
    "            if new_df_columns[col_index-1] == 'DATA COUNT':\n",
    "                new_df_columns[col_index] = f\"DATA CAP. ({new_df_columns[col_index-2]})\"\n",
    "            else:\n",
    "                new_df_columns[col_index] = f\"DATA CAP. ({new_df_columns[col_index-1]})\"\n",
    "\n",
    "    # Set the new header\n",
    "    df3.columns = new_df_columns.str.upper().values\n",
    "\n",
    "    # Display the DataFrame\n",
    "    df3 = df3.drop([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "    df3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # Mapping the original column names to new column names\n",
    "    column_mapping = {\n",
    "        'DATE/TIME': 'DATE/TIME',    'SO2': 'SO2',    'DATA CAP. (SO2)': 'DATA CAP. (SO2)',    'SO2 AVG': 'SO2 AVG',    'NO2': 'NO2',    'DATA CAP. (NO2)': 'DATA CAP. (NO2)',    'NO2 AVG': 'NO2 AVG',    'O3': 'O3',    'DATA CAP. (O3)': 'DATA CAP. (O3)',    'O3 8H AVG.': 'O3 8H AVG.',    'DAILY CAPTURE': 'DAILY CAPTURE',    'O3 DAILY AVERAGE': 'O3 DAILY AVERAGE',    'O3 DAILY AVERAGE (NS)': 'O3 DAILY AVERAGE (NS)',    'CO': 'CO',    'DATA CAP. (CO)': 'DATA CAP. (CO)',    'CO 8H AVG.': 'CO 8H AVG.',    'DAILY CAPTURE': 'DAILY CAPTURE',    'CO DAILY AVERAGE': 'CO DAILY AVERAGE',    'PM10': 'PM10',    'DATA CAP. (PM10)': 'DATA CAP. (PM10)',    'PM10 AVG': 'PM10 AVG',    'PM2.5': 'PM2.5',    'DATA CAP. (PM2.5)': 'DATA CAP. (PM2.5)',    'PM2.5 AVG': 'PM2.5 AVG',    'LOWER AMBIENT TEMPERATURE': 'LOWER AMBIENT TEMPERATURE',    'UPPER AMBIENT TEMPERATURE': 'UPPER AMBIENT TEMPERATURE',    'BAROMETRIC PRESSURE': 'BAROMETRIC PRESSURE',    'RELATIVEHUMIDITY': 'RELATIVE HUMIDITY',    'WIND DIRECTION': 'WIND DIRECTION',    'WIND SPEED': 'WIND SPEED',    'H2S': 'H2S',    'TOLUENE': 'TOLUENE',    'O_XYLENE': 'O_XYLENE',    'ETHYLBENZENE': 'ETHYLBENZENE',    'MP_XYLENE_': 'MP_XYLENE_',    'BENZENE': 'BENZENE',    'CH4': 'CH4',    'NMHC': 'NMHC',    'THC': 'THC',    'NOISE': 'NOISE'\n",
    "    }\n",
    "\n",
    "    df3 = df3.rename(columns=column_mapping)\n",
    "    df3.insert(0, 'STATION NAME', excel_file.sheet_names[sheet_index])\n",
    "    df3[\"DATE/TIME\"] = pd.to_datetime(df3[\"DATE/TIME\"], format='%m/%d/%Y %H:%M:%S')\n",
    "    df3[\"DATE/TIME\"] = df3[\"DATE/TIME\"].dt.strftime('%d/%m/%Y %H:%M:%S')\n",
    "    df3.to_csv(f'/workspaces/vikrant_dubai/Transformed/{excel_file.sheet_names[sheet_index]}.csv', index=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get a list of all CSV files in the transformed folder\n",
    "csv_files = [f for f in os.listdir('/workspaces/vikrant_dubai/Transformed') if f.endswith('.csv')]\n",
    "\n",
    "# Read and concatenate all CSV files\n",
    "combined_df = pd.concat([pd.read_csv(os.path.join('/workspaces/vikrant_dubai/Transformed', f)) for f in csv_files], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv('/workspaces/vikrant_dubai/final/combined.csv', index=False)\n",
    "\n",
    "\n",
    "# Get a list of all files in the Transformed folder\n",
    "files = glob.glob('/workspaces/vikrant_dubai/Transformed/*')\n",
    "\n",
    "# Iterate over the list of files and remove each one\n",
    "for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # df3 = df3.drop(df3.index[:4])\n",
    "    # df3.columns = df3.iloc[0:3].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=0)\n",
    "    # df3 = df3[3:]\n",
    "    # df3.reset_index(drop=True, inplace=True)\n",
    "    # df3.insert(0, 'Station Name', excel_file.sheet_names[i])\n",
    "    # # df3.to_csv(f'/workspaces/vikrant_dubai/Transformed/{excel_file.sheet_names[i]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
