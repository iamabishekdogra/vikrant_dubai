{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3431/4208464079.py:1: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/workspaces/vikrant_dubai/final/comb/DXB_combined.csv')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('/workspaces/vikrant_dubai/final/comb/DXB_combined.csv')\n",
    "unique_station_names = df['Station Name'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EmiratesHills', 'NadAlShiba', 'DIP', 'JAVillage', 'Hatta',\n",
       "       'Karama', 'AlQusais', 'Warsan', 'Zabeel', 'ShkZayedRd',\n",
       "       'ShkMohdBinZayedRd', 'Deira', 'Airport', 'Mushrif',\n",
       "       'MushrifNationalPark'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_station_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df[['Station Name', 'Date', 'Time', 'NO2']]\n",
    "no2 = df2[df2['Time'] == '01:00:00'].copy()\n",
    "no2['Date'] = pd.to_datetime(no2['Date'], dayfirst=True)\n",
    "no2['vlookup'] = no2['Station Name'].str[:5] + no2['Date'].dt.strftime('%d%m%Y')\n",
    "no2 = no2[['vlookup', 'NO2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finder_table(df):\n",
    "    df['vlookup'] = df['Station Name'].str[:3] + df['Date'].str.replace('/', '')\n",
    "    df_grouped = df.groupby(['Station Name', 'Date']).first().reset_index()\n",
    "    df_grouped['vlookup'] = df_grouped['Station Name'].str[:5] + df_grouped['Date'].str.replace('/', '')\n",
    "    Finder_table = df_grouped[['Station Name', 'Date', 'vlookup']]\n",
    "    return Finder_table\n",
    "\n",
    "# Example usage:\n",
    "Finder_table = create_finder_table(df)\n",
    "Finder_table.to_csv('/workspaces/vikrant_dubai/SQL/Finder_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Station Name', 'Date', 'Time', 'SO2', 'Data Cap. (SO2)', 'SO2 Avg',\n",
       "       'NO2', 'Data Cap. (NO2)', 'NO2 Avg', 'O3', 'Data Cap. (O3)',\n",
       "       'O3 8H Avg.', 'Daily Capture O3', 'O3 Daily Average',\n",
       "       'O3 Daily Average (NS)', 'CO', 'Data Cap. (CO)', 'CO 8H Avg.',\n",
       "       'Daily Capture CO', 'CO Daily Average', 'PM10', 'Data Cap. (PM10)',\n",
       "       'PM10 Avg', 'PM2.5', 'Data Cap. (PM2.5)', 'PM2.5 Avg',\n",
       "       'Lower Ambient Temperature', 'Upper Ambient Temperature',\n",
       "       'Barometric Pressure', 'Relative Humidity', 'Wind Direction',\n",
       "       'Wind Speed', 'H2S', 'Toluene', 'O-Xylene', 'Ethylbenzene', 'MP-Xylene',\n",
       "       'Benzene', 'CH4', 'NMHC', 'THC', 'Noise', 'Solar Radiation', 'Atm P.',\n",
       "       'NAN', 'vlookup'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pollutants to process others\n",
    "\n",
    "pollutants = ['Lower Ambient Temperature', 'Upper Ambient Temperature',\n",
    "       'Barometric Pressure', 'Relative Humidity', 'Wind Direction',\n",
    "       'Wind Speed', 'H2S', 'Toluene', 'O-Xylene', 'Ethylbenzene', 'MP-Xylene',\n",
    "       'Benzene', 'CH4', 'NMHC', 'THC', 'Noise', 'Solar Radiation', 'Atm P.']\n",
    "\n",
    "# Convert pollutant columns to numeric, forcing errors to NaN\n",
    "df[pollutants] = df[pollutants].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "avg_values = df.groupby(['Station Name', 'Date'])[pollutants].mean().reset_index()\n",
    "\n",
    "final_df = pd.merge(avg_values, Finder_table, on=['Station Name', 'Date'], suffixes=(' Avg 24H', ''))\n",
    "final_df.rename(columns={'Station Name': 'Name'}, inplace=True)\n",
    "final_df['vlookup'] = final_df['Name'].str[:5] + final_df['Date'].str.replace('/', '')\n",
    "final_df=final_df.drop(columns=['Name', 'Date'])\n",
    "final_df = final_df[['vlookup'] + [col for col in final_df.columns if col != 'vlookup']]\n",
    "final_df.to_csv('/workspaces/vikrant_dubai/SQL/other.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>vlookup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.908333</td>\n",
       "      <td>28.313750</td>\n",
       "      <td>1.162500</td>\n",
       "      <td>1.059583</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>Ajman01012023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.296667</td>\n",
       "      <td>26.647083</td>\n",
       "      <td>1.319167</td>\n",
       "      <td>23.330833</td>\n",
       "      <td>7.953750</td>\n",
       "      <td>Ajman01022023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.155000</td>\n",
       "      <td>29.250417</td>\n",
       "      <td>0.584583</td>\n",
       "      <td>17.247500</td>\n",
       "      <td>8.151667</td>\n",
       "      <td>Ajman01032023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.024583</td>\n",
       "      <td>17.529167</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>24.255000</td>\n",
       "      <td>9.757917</td>\n",
       "      <td>Ajman01042023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.935417</td>\n",
       "      <td>33.590833</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ajman01052023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>3.886333</td>\n",
       "      <td>4.394500</td>\n",
       "      <td>0.162237</td>\n",
       "      <td>79.647500</td>\n",
       "      <td>33.690417</td>\n",
       "      <td>Masfo31052023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>5.227808</td>\n",
       "      <td>14.374129</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>45.990417</td>\n",
       "      <td>18.035417</td>\n",
       "      <td>Masfo31072023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>6.245158</td>\n",
       "      <td>10.898500</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>43.170833</td>\n",
       "      <td>19.293333</td>\n",
       "      <td>Masfo31082023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>4.120258</td>\n",
       "      <td>17.298975</td>\n",
       "      <td>0.150417</td>\n",
       "      <td>15.979583</td>\n",
       "      <td>6.572917</td>\n",
       "      <td>Masfo31102023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>8.712504</td>\n",
       "      <td>26.662792</td>\n",
       "      <td>0.279583</td>\n",
       "      <td>30.811250</td>\n",
       "      <td>11.532917</td>\n",
       "      <td>Masfo31122023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1825 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SO2        NO2        CO       PM10      PM2.5        vlookup\n",
       "0     1.908333  28.313750  1.162500   1.059583   0.085417  Ajman01012023\n",
       "1     1.296667  26.647083  1.319167  23.330833   7.953750  Ajman01022023\n",
       "2     2.155000  29.250417  0.584583  17.247500   8.151667  Ajman01032023\n",
       "3     2.024583  17.529167  0.818333  24.255000   9.757917  Ajman01042023\n",
       "4     2.935417  33.590833  0.326667        NaN        NaN  Ajman01052023\n",
       "...        ...        ...       ...        ...        ...            ...\n",
       "1820  3.886333   4.394500  0.162237  79.647500  33.690417  Masfo31052023\n",
       "1821  5.227808  14.374129  0.216667  45.990417  18.035417  Masfo31072023\n",
       "1822  6.245158  10.898500  0.202500  43.170833  19.293333  Masfo31082023\n",
       "1823  4.120258  17.298975  0.150417  15.979583   6.572917  Masfo31102023\n",
       "1824  8.712504  26.662792  0.279583  30.811250  11.532917  Masfo31122023\n",
       "\n",
       "[1825 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "pollutants = ['SO2', 'NO2','CO','PM10', 'PM2.5']\n",
    "\n",
    "# Convert pollutant columns to numeric, forcing errors to NaN\n",
    "df[pollutants] = df[pollutants].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "avg_values = df.groupby(['Station Name', 'Date'])[pollutants].mean().reset_index()\n",
    "\n",
    "final_df = pd.merge(avg_values, Finder_table, on=['Station Name', 'Date'], suffixes=(' Avg 24H', ''))\n",
    "final_df.rename(columns={'Station Name': 'Name'}, inplace=True)\n",
    "final_df['vlookup'] = final_df['Name'].str[:5] + final_df['Date'].str.replace('/', '')\n",
    "final_df=final_df.drop(columns=['Name', 'Date'])\n",
    "final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "allother=final_df[['vlookup', 'SO2','PM10', 'PM2.5']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39003/4184489898.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_columns['O3'] = pd.to_numeric(selected_columns['O3'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "selected_columns = df[['Station Name', 'Date','Time', 'O3']]\n",
    "\n",
    "# Convert 'O3' column to numeric type\n",
    "selected_columns['O3'] = pd.to_numeric(selected_columns['O3'], errors='coerce')\n",
    "\n",
    "\n",
    "# Extract unique station names\n",
    "unique_station_names = selected_columns[\"Station Name\"].unique()\n",
    "\n",
    "# Define the process_data function\n",
    "def process_data(values, dates, times):\n",
    "    # Create DataFrame\n",
    "    df_temp = pd.DataFrame({'Index': range(len(values)), 'Values': values, 'Date': dates, 'Time': times})\n",
    "\n",
    "    # Calculate 8-hour moving average\n",
    "    df_temp['8h_Avg'] = df_temp['Values'].rolling(window=8).mean()\n",
    "\n",
    "    # Calculate datacap (percentage of available data in 8-hour window)\n",
    "    df_temp['datacap'] = df_temp['Values'].rolling(window=8).count() / 8 * 100\n",
    "\n",
    "    # Ensure first 7 values of 'datacap' are blank (NaN)\n",
    "    #df_temp.loc[:6, 'datacap'] = None\n",
    "\n",
    "    # Define function to calculate 8h_Avg_WHO and 8h_Avg_NS\n",
    "    def calculate_adjusted_avg(df_temp, max_threshold):\n",
    "        adjusted_avg = [None] * len(df_temp)\n",
    "        for i in range(7, len(df_temp)):\n",
    "            if df_temp.loc[i, 'datacap'] >= 75:\n",
    "                adjusted_avg[i] = df_temp.loc[i, '8h_Avg']\n",
    "            else:\n",
    "                max_value = df_temp.loc[i-7:i, 'Values'].max()\n",
    "                if max_value > max_threshold:\n",
    "                    adjusted_avg[i] = max_value\n",
    "        return adjusted_avg\n",
    "\n",
    "    # Calculate 8h_Avg_WHO with max value threshold of 100\n",
    "    df_temp['8h_Avg_WHO'] = calculate_adjusted_avg(df_temp, 100)\n",
    "\n",
    "    # Calculate 8h_Avg_NS with max value threshold of 120\n",
    "    df_temp['8h_Avg_NS'] = calculate_adjusted_avg(df_temp, 120)\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "# Process data for each station name\n",
    "dfs = []\n",
    "for station in unique_station_names:\n",
    "    station_data = selected_columns[selected_columns['Station Name'] == station]\n",
    "    station_values = station_data[\"O3\"].tolist()\n",
    "    station_dates = station_data[\"Date\"].tolist()\n",
    "    station_times = station_data[\"Time\"].tolist()\n",
    "    processed_df = process_data(station_values, station_dates, station_times)\n",
    "    processed_df['Station Name'] = station\n",
    "    dfs.append(processed_df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df2 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rearrange the columns as specified\n",
    "df2 = df2[['Station Name', 'Date','Time', 'Values', 'datacap', '8h_Avg_WHO', '8h_Avg_NS']]\n",
    "df2.rename(columns={'Values': 'O3'}, inplace=True)\n",
    "\n",
    "# Convert 'Date' column to datetime format for proper grouping\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], dayfirst=True)\n",
    "\n",
    "# Calculate 8h_Avg_WHO_DC and 8h_Avg_NS_DC\n",
    "df2['8h_Avg_WHO_DC'] = df2.groupby(['Station Name', 'Date'])['8h_Avg_WHO'].transform(lambda x: x.count() / 24 * 100)\n",
    "df2['8h_Avg_NS_DC'] = df2.groupby(['Station Name', 'Date'])['8h_Avg_NS'].transform(lambda x: x.count() / 24 * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39003/3625366439.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  o3['vlookup'] = o3['Station Name'].str[:5] + o3['Date'].dt.strftime('%d%m%Y')\n"
     ]
    }
   ],
   "source": [
    "o3=df2[df2['Time'] == '08:00:00']\n",
    "o3['vlookup'] = o3['Station Name'].str[:5] + o3['Date'].dt.strftime('%d%m%Y')\n",
    "o3=o3[['vlookup','8h_Avg_WHO', '8h_Avg_NS']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vlookup</th>\n",
       "      <th>Time</th>\n",
       "      <th>O3</th>\n",
       "      <th>datacap</th>\n",
       "      <th>8h_Avg_WHO</th>\n",
       "      <th>8h_Avg_NS</th>\n",
       "      <th>8h_Avg_WHO_DC</th>\n",
       "      <th>8h_Avg_NS_DC</th>\n",
       "      <th>Daily_Avg_8h_WHO</th>\n",
       "      <th>Daily_Avg_8h_NS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jurf01012023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>1.9632</td>\n",
       "      <td>100.0</td>\n",
       "      <td>37.05540</td>\n",
       "      <td>37.05540</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jurf02012023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>53.0064</td>\n",
       "      <td>100.0</td>\n",
       "      <td>46.87140</td>\n",
       "      <td>46.87140</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>37.89385</td>\n",
       "      <td>37.89385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jurf03012023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>62.8224</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.32540</td>\n",
       "      <td>49.32540</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>49.7344</td>\n",
       "      <td>49.7344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jurf04012023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>76.5648</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.81020</td>\n",
       "      <td>76.81020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.249825</td>\n",
       "      <td>67.249825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jurf05012023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>64.7856</td>\n",
       "      <td>100.0</td>\n",
       "      <td>47.11680</td>\n",
       "      <td>47.11680</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.331625</td>\n",
       "      <td>67.331625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>Ajman27122023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.52750</td>\n",
       "      <td>4.52750</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.193437</td>\n",
       "      <td>20.193437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>Ajman28122023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.82375</td>\n",
       "      <td>12.82375</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>26.052812</td>\n",
       "      <td>26.052812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>Ajman29122023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.01750</td>\n",
       "      <td>18.01750</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>28.507552</td>\n",
       "      <td>28.507552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>Ajman30122023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.02875</td>\n",
       "      <td>6.02875</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>25.303646</td>\n",
       "      <td>25.303646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Ajman31122023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>8.6100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.29125</td>\n",
       "      <td>31.29125</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.01875</td>\n",
       "      <td>27.01875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            vlookup      Time       O3  datacap  8h_Avg_WHO  8h_Avg_NS  \\\n",
       "0      Jurf01012023  23:00:00   1.9632    100.0    37.05540   37.05540   \n",
       "1      Jurf02012023  23:00:00  53.0064    100.0    46.87140   46.87140   \n",
       "2      Jurf03012023  23:00:00  62.8224    100.0    49.32540   49.32540   \n",
       "3      Jurf04012023  23:00:00  76.5648    100.0    76.81020   76.81020   \n",
       "4      Jurf05012023  23:00:00  64.7856    100.0    47.11680   47.11680   \n",
       "...             ...       ...      ...      ...         ...        ...   \n",
       "1821  Ajman27122023  23:00:00   0.0900    100.0     4.52750    4.52750   \n",
       "1822  Ajman28122023  23:00:00   0.0600    100.0    12.82375   12.82375   \n",
       "1823  Ajman29122023  23:00:00   0.2200    100.0    18.01750   18.01750   \n",
       "1824  Ajman30122023  23:00:00   0.0400    100.0     6.02875    6.02875   \n",
       "1825  Ajman31122023  23:00:00   8.6100    100.0    31.29125   31.29125   \n",
       "\n",
       "      8h_Avg_WHO_DC  8h_Avg_NS_DC Daily_Avg_8h_WHO Daily_Avg_8h_NS  \n",
       "0         70.833333     70.833333             None            None  \n",
       "1        100.000000    100.000000         37.89385        37.89385  \n",
       "2        100.000000    100.000000          49.7344         49.7344  \n",
       "3        100.000000    100.000000        67.249825       67.249825  \n",
       "4        100.000000    100.000000        67.331625       67.331625  \n",
       "...             ...           ...              ...             ...  \n",
       "1821     100.000000    100.000000        20.193437       20.193437  \n",
       "1822     100.000000    100.000000        26.052812       26.052812  \n",
       "1823     100.000000    100.000000        28.507552       28.507552  \n",
       "1824     100.000000    100.000000        25.303646       25.303646  \n",
       "1825     100.000000    100.000000         27.01875        27.01875  \n",
       "\n",
       "[1826 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Ensure only the last row of each day for each station retains the values, setting others to NaN\n",
    "df2.loc[df2.duplicated(subset=['Station Name', 'Date'], keep='last'), ['8h_Avg_WHO_DC', '8h_Avg_NS_DC']] = None\n",
    "\n",
    "# Group by 'Station Name' and 'Date'\n",
    "grouped = df2.groupby(['Station Name', 'Date'])\n",
    "\n",
    "# Create new columns for the calculated daily averages\n",
    "df2['Daily_Avg_8h_WHO'] = None\n",
    "df2['Daily_Avg_8h_NS'] = None\n",
    "\n",
    "# Iterate over each group to calculate the averages where count > 75\n",
    "for (station, date), group in grouped:\n",
    "    if group['8h_Avg_WHO_DC'].sum() > 75:  # Check if total count > 75 for WHO\n",
    "        avg_value_who = group['8h_Avg_WHO'].mean()  # Calculate average for WHO\n",
    "        df2.loc[group.index[-1], 'Daily_Avg_8h_WHO'] = avg_value_who  # Assign to last row\n",
    "    \n",
    "    if group['8h_Avg_NS_DC'].sum() > 75:  # Check if total count > 75 for NS\n",
    "        avg_value_ns = group['8h_Avg_NS'].mean()  # Calculate average for NS\n",
    "        df2.loc[group.index[-1], 'Daily_Avg_8h_NS'] = avg_value_ns  # Assign to last row\n",
    "\n",
    "\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], dayfirst=True)\n",
    "\n",
    "# Change date format to ddmmyyyy\n",
    "df2['Date'] = df2['Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Add a new column 'vlookup' that takes the first 5 letters of 'Station Name' and concatenates it with 'Date'\n",
    "df2['vlookup'] = df2['Station Name'].str[:5] + df2['Date'].str.replace('/', '')\n",
    "\n",
    "# Remove the 'Station Name' column\n",
    "df2.drop(columns=['Station Name','Date'], inplace=True)\n",
    "\n",
    "\n",
    "last_rows_per_date_station = df2.drop_duplicates(subset=['vlookup'], keep='last')\n",
    "\n",
    "last_rows_per_date_station = last_rows_per_date_station[['vlookup'] + [col for col in last_rows_per_date_station.columns if col != 'vlookup']]\n",
    "\n",
    "# Reset the index\n",
    "last_rows_per_date_station.reset_index(drop=True, inplace=True)\n",
    "\n",
    "last_rows_per_date_station\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "selected_columns = df[['Station Name', 'Date','Time', 'CO']]\n",
    "\n",
    "df=selected_columns\n",
    "\n",
    "# Convert 'Date' column to datetime format for proper processing\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "\n",
    "# Extract unique station names\n",
    "unique_station_names = df[\"Station Name\"].unique()\n",
    "\n",
    "# Define the process_data function for CO transformation\n",
    "def process_data(values, dates, times):\n",
    "    # Create DataFrame\n",
    "    df_temp = pd.DataFrame({'Index': range(len(values)), 'CO': values, 'Date': dates, 'Time': times})\n",
    "\n",
    "    # Calculate 8-hour moving average\n",
    "    df_temp['C0_8h_Avg'] = df_temp['CO'].rolling(window=8).mean()\n",
    "\n",
    "    # Calculate datacap (percentage of available data in 8-hour window)\n",
    "    df_temp['datacap'] = df_temp['CO'].rolling(window=8).count() / 8 * 100\n",
    "\n",
    "    # Ensure first 7 values of 'datacap' are blank (NaN)\n",
    "    df_temp.loc[:6, 'datacap'] = None\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "# Process data for each station name\n",
    "dfs = []\n",
    "for station in unique_station_names:\n",
    "    station_data = df[df['Station Name'] == station]\n",
    "    station_values = station_data[\"CO\"].tolist()\n",
    "    station_dates = station_data[\"Date\"].tolist()\n",
    "    station_times = station_data[\"Time\"].tolist()\n",
    "    processed_df = process_data(station_values, station_dates, station_times)\n",
    "    processed_df['Station Name'] = station\n",
    "    dfs.append(processed_df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df2 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rearrange the columns as specified\n",
    "df2 = df2[['Station Name', 'Date', 'Time', 'CO', 'datacap', 'C0_8h_Avg']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39003/467830704.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  co['vlookup'] = co['Station Name'].str[:5] + co['Date'].dt.strftime('%d%m%Y')\n"
     ]
    }
   ],
   "source": [
    "co=df2[df2['Time'] == '08:00:00']\n",
    "co['vlookup'] = co['Station Name'].str[:5] + co['Date'].dt.strftime('%d%m%Y')\n",
    "co=co[['vlookup', 'C0_8h_Avg']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge co, o3, and allother DataFrames on 'vlookup'\n",
    "combined = allother.merge(o3, on='vlookup', how='outer').merge(co, on='vlookup', how='outer').merge(no2, on='vlookup', how='outer')\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined.to_csv('/workspaces/vikrant_dubai/SQL/AQI.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vlookup</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO</th>\n",
       "      <th>datacap</th>\n",
       "      <th>C0_8h_Avg</th>\n",
       "      <th>C0_8h_Avg_DC</th>\n",
       "      <th>Daily_Avg_8h_C0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jurf01012023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.984872</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.734359</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jurf02012023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.309204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.493629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jurf03012023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.194684</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.294889</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.272701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jurf04012023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.148876</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.187526</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.211027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jurf05012023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.160328</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.271985</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.20715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>Ajman27122023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.467500</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.127552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>Ajman28122023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.296250</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.987031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>Ajman29122023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>2.670000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.992500</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.820885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>Ajman30122023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>4.070000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.440000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.748698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Ajman31122023</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.503750</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.763281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            vlookup      Time        CO  datacap  C0_8h_Avg  C0_8h_Avg_DC  \\\n",
       "0      Jurf01012023  23:00:00  0.984872    100.0   0.734359     70.833333   \n",
       "1      Jurf02012023  23:00:00  0.309204    100.0   0.303478    100.000000   \n",
       "2      Jurf03012023  23:00:00  0.194684    100.0   0.294889    100.000000   \n",
       "3      Jurf04012023  23:00:00  0.148876    100.0   0.187526    100.000000   \n",
       "4      Jurf05012023  23:00:00  0.160328    100.0   0.271985    100.000000   \n",
       "...             ...       ...       ...      ...        ...           ...   \n",
       "1821  Ajman27122023  23:00:00  3.510000    100.0   3.467500    100.000000   \n",
       "1822  Ajman28122023  23:00:00  3.230000    100.0   3.296250    100.000000   \n",
       "1823  Ajman29122023  23:00:00  2.670000    100.0   2.992500    100.000000   \n",
       "1824  Ajman30122023  23:00:00  4.070000    100.0   3.440000    100.000000   \n",
       "1825  Ajman31122023  23:00:00  2.840000    100.0   2.503750    100.000000   \n",
       "\n",
       "     Daily_Avg_8h_C0  \n",
       "0               None  \n",
       "1           0.493629  \n",
       "2           0.272701  \n",
       "3           0.211027  \n",
       "4            0.20715  \n",
       "...              ...  \n",
       "1821        3.127552  \n",
       "1822        2.987031  \n",
       "1823        2.820885  \n",
       "1824        2.748698  \n",
       "1825        2.763281  \n",
       "\n",
       "[1826 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Calculate C0_8h_Avg_DC (daily data capture percentage for CO 8h Avg)\n",
    "df2['C0_8h_Avg_DC'] = df2.groupby(['Station Name', 'Date'])['C0_8h_Avg'].transform(lambda x: x.count() / 24 * 100)\n",
    "\n",
    "# Ensure only the last row of each day for each station retains the values, setting others to NaN\n",
    "df2.loc[df2.duplicated(subset=['Station Name', 'Date'], keep='last'), ['C0_8h_Avg_DC']] = None\n",
    "\n",
    "# Group by 'Station Name' and 'Date'\n",
    "grouped = df2.groupby(['Station Name', 'Date'])\n",
    "\n",
    "# Create new columns for the calculated daily averages\n",
    "df2['Daily_Avg_8h_C0'] = None\n",
    "\n",
    "# Iterate over each group to calculate the daily averages where count > 75\n",
    "for (station, date), group in grouped:\n",
    "    if group['C0_8h_Avg_DC'].sum() > 75:  # Check if total count > 75\n",
    "        avg_value_c0 = group['C0_8h_Avg'].mean()  # Calculate average\n",
    "        df2.loc[group.index[-1], 'Daily_Avg_8h_C0'] = avg_value_c0  # Assign to last row\n",
    "\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], dayfirst=True)\n",
    "\n",
    "# Change date format to ddmmyyyy\n",
    "df2['Date'] = df2['Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Add a new column 'vlookup' that takes the first 5 letters of 'Station Name' and concatenates it with 'Date'\n",
    "df2['vlookup'] = df2['Station Name'].str[:5] + df2['Date'].str.replace('/', '')\n",
    "\n",
    "# Remove the 'Station Name' column\n",
    "df2.drop(columns=['Station Name','Date'], inplace=True)\n",
    "\n",
    "\n",
    "last_rows_per_date_station2 = df2.drop_duplicates(subset=['vlookup'], keep='last')\n",
    "\n",
    "last_rows_per_date_station2 = last_rows_per_date_station2[['vlookup'] + [col for col in last_rows_per_date_station2.columns if col != 'vlookup']]\n",
    "\n",
    "# Reset the index\n",
    "last_rows_per_date_station2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "last_rows_per_date_station2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Merge last_rows_per_date_station and last_rows_per_date_station2 on 'vlookup'\n",
    "combined_df = pd.merge(last_rows_per_date_station, last_rows_per_date_station2, on='vlookup', suffixes=('_O3', '_CO'))\n",
    "\n",
    "# Merge the result with final_df on 'vlookup'\n",
    "combined_df = pd.merge(combined_df, final_df, on='vlookup')\n",
    "\n",
    "# Display the combined dataframe\n",
    "D24hparameter=combined_df[['vlookup','SO2', 'NO2', 'Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0', 'PM10', 'PM2.5']]\n",
    "\n",
    "D24hparameter.to_csv('/workspaces/vikrant_dubai/SQL/D24hparameter.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Round all columns of D24hparameter to 1 decimal place\n",
    "D24hparameter_rounded = D24hparameter.round(1)\n",
    "# Convert 'Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', and 'Daily_Avg_8h_C0' to numeric, forcing errors to NaN\n",
    "D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']] = D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Round the specified columns to 1 decimal place\n",
    "D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']] = D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']].round(1)\n",
    "# Display the new table\n",
    "D24hparameter_rounded.to_csv('/workspaces/vikrant_dubai/SQL/D24hparameter_rounded.csv', index=False)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df=D24hparameter_rounded\n",
    "\n",
    "# Create a new DataFrame KPI_NS containing only the 'vlookup' column\n",
    "KPI_NS = df[['vlookup']].copy()\n",
    "\n",
    "# Add 'SO2' column based on the condition\n",
    "KPI_NS['SO2'] = df['SO2'].apply(lambda x: 1 if x < 150.4 else 0)\n",
    "\n",
    "# Add 'NO2' column based on the condition\n",
    "KPI_NS['NO2'] = df['NO2'].apply(lambda x: 1 if x < 150.4 else 0)\n",
    "\n",
    "# Add 'O3' column based on the condition using 'Daily_Avg_8h_NS'\n",
    "KPI_NS['O3'] = df['Daily_Avg_8h_NS'].apply(lambda x: 1 if x < 120.4 else 0)\n",
    "\n",
    "# Add 'CO' column based on the condition using 'Daily_Avg_8h_C0'\n",
    "KPI_NS['CO'] = df['Daily_Avg_8h_C0'].apply(lambda x: 1 if x < 10.4 else 0)\n",
    "\n",
    "\n",
    "KPI_NS.to_csv('/workspaces/vikrant_dubai/SQL/KPI_NS.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "df=D24hparameter_rounded\n",
    "\n",
    "# Create a new DataFrame KPI_NS containing only the 'vlookup' column\n",
    "KPI_WHO = df[['vlookup']].copy()\n",
    "\n",
    "# Add 'SO2' column based on the condition\n",
    "KPI_WHO['SO2'] = df['SO2'].apply(lambda x: 1 if x < 20.4 else 0)\n",
    "\n",
    "# Add 'NO2' column based on the condition\n",
    "KPI_WHO['NO2'] = df['NO2'].apply(lambda x: 1 if x < 75.4 else 0)\n",
    "\n",
    "# Add 'O3' column based on the condition using 'Daily_Avg_8h_NS'\n",
    "KPI_WHO['O3'] = df['Daily_Avg_8h_NS'].apply(lambda x: 1 if x < 100.4 else 0)\n",
    "\n",
    "# Add 'CO' column based on the condition using 'Daily_Avg_8h_C0'\n",
    "KPI_WHO['CO'] = df['Daily_Avg_8h_C0'].apply(lambda x: 1 if x < 10.4 else 0)\n",
    "\n",
    "\n",
    "KPI_WHO.to_csv('/workspaces/vikrant_dubai/SQL/KPI_WHO.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "KPI_PM = df[['vlookup']].copy()\n",
    "KPI_PM['PM10'] = df['PM10'].apply(lambda x: 1 if x < 150.4 else 0)\n",
    "KPI_PM['PM2.5'] = df['PM2.5'].apply(lambda x: 1 if x < 60.4 else 0)\n",
    "KPI_PM.to_csv('/workspaces/vikrant_dubai/SQL/KPI_PM.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
