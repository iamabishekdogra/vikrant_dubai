{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5558/1962484940.py:1: DtypeWarning: Columns (6,9,15,23,27,29,39,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/workspaces/vikrant_dubai/final/comb/AJ_combined.csv')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('/workspaces/vikrant_dubai/final/comb/AJ_combined.csv')\n",
    "unique_station_names = df['Station Name'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Masfout', 'Envi', 'AjmanX', 'Manama', 'Jurf'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_station_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finder_table(df):\n",
    "    df['vlookup'] = df['Station Name'].str[:3] + df['Date'].str.replace('/', '')\n",
    "    df_grouped = df.groupby(['Station Name', 'Date']).first().reset_index()\n",
    "    df_grouped['vlookup'] = df_grouped['Station Name'].str[:5] + df_grouped['Date'].str.replace('/', '')\n",
    "    Finder_table = df_grouped[['Station Name', 'Date', 'vlookup']]\n",
    "    return Finder_table\n",
    "\n",
    "# Example usage:\n",
    "Finder_table = create_finder_table(df)\n",
    "Finder_table.to_csv('/workspaces/vikrant_dubai/SQL/Finder_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>vlookup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.908333</td>\n",
       "      <td>28.313750</td>\n",
       "      <td>1.162500</td>\n",
       "      <td>1.059583</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>Ajman01012023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.296667</td>\n",
       "      <td>26.647083</td>\n",
       "      <td>1.319167</td>\n",
       "      <td>23.330833</td>\n",
       "      <td>7.953750</td>\n",
       "      <td>Ajman01022023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.155000</td>\n",
       "      <td>29.250417</td>\n",
       "      <td>0.584583</td>\n",
       "      <td>17.247500</td>\n",
       "      <td>8.151667</td>\n",
       "      <td>Ajman01032023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.024583</td>\n",
       "      <td>17.529167</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>24.255000</td>\n",
       "      <td>9.757917</td>\n",
       "      <td>Ajman01042023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.935417</td>\n",
       "      <td>33.590833</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ajman01052023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>3.886333</td>\n",
       "      <td>4.394500</td>\n",
       "      <td>0.162237</td>\n",
       "      <td>79.647500</td>\n",
       "      <td>33.690417</td>\n",
       "      <td>Masfo31052023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>5.227808</td>\n",
       "      <td>14.374129</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>45.990417</td>\n",
       "      <td>18.035417</td>\n",
       "      <td>Masfo31072023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>6.245158</td>\n",
       "      <td>10.898500</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>43.170833</td>\n",
       "      <td>19.293333</td>\n",
       "      <td>Masfo31082023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>4.120258</td>\n",
       "      <td>17.298975</td>\n",
       "      <td>0.150417</td>\n",
       "      <td>15.979583</td>\n",
       "      <td>6.572917</td>\n",
       "      <td>Masfo31102023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>8.712504</td>\n",
       "      <td>26.662792</td>\n",
       "      <td>0.279583</td>\n",
       "      <td>30.811250</td>\n",
       "      <td>11.532917</td>\n",
       "      <td>Masfo31122023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1825 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SO2        NO2        CO       PM10      PM2.5        vlookup\n",
       "0     1.908333  28.313750  1.162500   1.059583   0.085417  Ajman01012023\n",
       "1     1.296667  26.647083  1.319167  23.330833   7.953750  Ajman01022023\n",
       "2     2.155000  29.250417  0.584583  17.247500   8.151667  Ajman01032023\n",
       "3     2.024583  17.529167  0.818333  24.255000   9.757917  Ajman01042023\n",
       "4     2.935417  33.590833  0.326667        NaN        NaN  Ajman01052023\n",
       "...        ...        ...       ...        ...        ...            ...\n",
       "1820  3.886333   4.394500  0.162237  79.647500  33.690417  Masfo31052023\n",
       "1821  5.227808  14.374129  0.216667  45.990417  18.035417  Masfo31072023\n",
       "1822  6.245158  10.898500  0.202500  43.170833  19.293333  Masfo31082023\n",
       "1823  4.120258  17.298975  0.150417  15.979583   6.572917  Masfo31102023\n",
       "1824  8.712504  26.662792  0.279583  30.811250  11.532917  Masfo31122023\n",
       "\n",
       "[1825 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "pollutants = ['SO2', 'NO2','CO','PM10', 'PM2.5']\n",
    "\n",
    "# Convert pollutant columns to numeric, forcing errors to NaN\n",
    "df[pollutants] = df[pollutants].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "avg_values = df.groupby(['Station Name', 'Date'])[pollutants].mean().reset_index()\n",
    "\n",
    "final_df = pd.merge(avg_values, Finder_table, on=['Station Name', 'Date'], suffixes=(' Avg 24H', ''))\n",
    "final_df.rename(columns={'Station Name': 'Name'}, inplace=True)\n",
    "final_df['vlookup'] = final_df['Name'].str[:5] + final_df['Date'].str.replace('/', '')\n",
    "final_df=final_df.drop(columns=['Name', 'Date'])\n",
    "final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5558/443812646.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_columns['O3'] = pd.to_numeric(selected_columns['O3'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "selected_columns = df[['Station Name', 'Date', 'O3']]\n",
    "\n",
    "# Convert 'O3' column to numeric type\n",
    "selected_columns['O3'] = pd.to_numeric(selected_columns['O3'], errors='coerce')\n",
    "\n",
    "\n",
    "# Extract unique station names\n",
    "unique_station_names = selected_columns[\"Station Name\"].unique()\n",
    "\n",
    "# Define the process_data function\n",
    "def process_data(values, dates):\n",
    "    # Create DataFrame\n",
    "    df_temp = pd.DataFrame({'Index': range(len(values)), 'Values': values, 'Date': dates})\n",
    "\n",
    "    # Calculate 8-hour moving average\n",
    "    df_temp['8h_Avg'] = df_temp['Values'].rolling(window=8).mean()\n",
    "\n",
    "    # Calculate datacap (percentage of available data in 8-hour window)\n",
    "    df_temp['datacap'] = df_temp['Values'].rolling(window=8).count() / 8 * 100\n",
    "\n",
    "    # Ensure first 7 values of 'datacap' are blank (NaN)\n",
    "    df_temp.loc[:6, 'datacap'] = None\n",
    "\n",
    "    # Define function to calculate 8h_Avg_WHO and 8h_Avg_NS\n",
    "    def calculate_adjusted_avg(df_temp, max_threshold):\n",
    "        adjusted_avg = [None] * len(df_temp)\n",
    "        for i in range(7, len(df_temp)):\n",
    "            if df_temp.loc[i, 'datacap'] > 75:\n",
    "                adjusted_avg[i] = df_temp.loc[i, '8h_Avg']\n",
    "            else:\n",
    "                max_value = df_temp.loc[i-7:i, 'Values'].max()\n",
    "                if max_value > max_threshold:\n",
    "                    adjusted_avg[i] = max_value\n",
    "        return adjusted_avg\n",
    "\n",
    "    # Calculate 8h_Avg_WHO with max value threshold of 100\n",
    "    df_temp['8h_Avg_WHO'] = calculate_adjusted_avg(df_temp, 100)\n",
    "\n",
    "    # Calculate 8h_Avg_NS with max value threshold of 120\n",
    "    df_temp['8h_Avg_NS'] = calculate_adjusted_avg(df_temp, 120)\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "# Process data for each station name\n",
    "dfs = []\n",
    "for station in unique_station_names:\n",
    "    station_data = selected_columns[selected_columns['Station Name'] == station]\n",
    "    station_values = station_data[\"O3\"].tolist()\n",
    "    station_dates = station_data[\"Date\"].tolist()\n",
    "    processed_df = process_data(station_values, station_dates)\n",
    "    processed_df['Station Name'] = station\n",
    "    dfs.append(processed_df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df2 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rearrange the columns as specified\n",
    "df2 = df2[['Station Name', 'Date', 'Values', 'datacap', '8h_Avg_WHO', '8h_Avg_NS']]\n",
    "df2.rename(columns={'Values': 'O3'}, inplace=True)\n",
    "\n",
    "# Convert 'Date' column to datetime format for proper grouping\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], dayfirst=True)\n",
    "\n",
    "# Calculate 8h_Avg_WHO_DC and 8h_Avg_NS_DC\n",
    "df2['8h_Avg_WHO_DC'] = df2.groupby(['Station Name', 'Date'])['8h_Avg_WHO'].transform(lambda x: x.count() / 24 * 100)\n",
    "df2['8h_Avg_NS_DC'] = df2.groupby(['Station Name', 'Date'])['8h_Avg_NS'].transform(lambda x: x.count() / 24 * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Station Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "O3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "datacap",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8h_Avg_WHO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8h_Avg_NS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8h_Avg_WHO_DC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8h_Avg_NS_DC",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9784af16-05a3-465d-bad5-c5f659a4d602",
       "rows": [
        [
         "0",
         "Masfout",
         "2023-10-01 00:00:00",
         "108.304",
         null,
         null,
         null,
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "1",
         "Masfout",
         "2023-10-01 00:00:00",
         "111.036",
         null,
         null,
         null,
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "2",
         "Masfout",
         "2023-10-01 00:00:00",
         "113.208",
         null,
         null,
         null,
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "3",
         "Masfout",
         "2023-10-01 00:00:00",
         "114.394",
         null,
         null,
         null,
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "4",
         "Masfout",
         "2023-10-01 00:00:00",
         "107.518",
         null,
         null,
         null,
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "5",
         "Masfout",
         "2023-10-01 00:00:00",
         "101.747",
         null,
         null,
         null,
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "6",
         "Masfout",
         "2023-10-01 00:00:00",
         "77.227",
         null,
         null,
         null,
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "7",
         "Masfout",
         "2023-10-01 00:00:00",
         "82.777",
         "100.0",
         "102.026375",
         "102.026375",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "8",
         "Masfout",
         "2023-10-01 00:00:00",
         "98.927",
         "100.0",
         "100.85425000000001",
         "100.85425000000001",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "9",
         "Masfout",
         "2023-10-01 00:00:00",
         "113.962",
         "100.0",
         "101.22",
         "101.22",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "10",
         "Masfout",
         "2023-10-01 00:00:00",
         "139.67",
         "100.0",
         "104.52775",
         "104.52775",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "11",
         "Masfout",
         "2023-10-01 00:00:00",
         "157.068",
         "100.0",
         "109.862",
         "109.862",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "12",
         "Masfout",
         "2023-10-01 00:00:00",
         "163.853",
         "100.0",
         "116.903875",
         "116.903875",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "13",
         "Masfout",
         "2023-10-01 00:00:00",
         "167.446",
         "100.0",
         "125.11625000000001",
         "125.11625000000001",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "14",
         "Masfout",
         "2023-10-01 00:00:00",
         "154.867",
         "100.0",
         "134.82125000000002",
         "134.82125000000002",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "15",
         "Masfout",
         "2023-10-01 00:00:00",
         "149.342",
         "100.0",
         "143.141875",
         "143.141875",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "16",
         "Masfout",
         "2023-10-01 00:00:00",
         "149.332",
         "100.0",
         "149.44250000000002",
         "149.44250000000002",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "17",
         "Masfout",
         "2023-10-01 00:00:00",
         "141.312",
         "100.0",
         "152.86124999999998",
         "152.86124999999998",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "18",
         "Masfout",
         "2023-10-01 00:00:00",
         "119.982",
         "100.0",
         "150.40025",
         "150.40025",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "19",
         "Masfout",
         "2023-10-01 00:00:00",
         "105.412",
         "100.0",
         "143.94325",
         "143.94325",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "20",
         "Masfout",
         "2023-10-01 00:00:00",
         "98.851",
         "100.0",
         "135.818",
         "135.818",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "21",
         "Masfout",
         "2023-10-01 00:00:00",
         "103.353",
         "100.0",
         "127.806375",
         "127.806375",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "22",
         "Masfout",
         "2023-10-01 00:00:00",
         "109.517",
         "100.0",
         "122.137625",
         "122.137625",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "23",
         "Masfout",
         "2023-10-01 00:00:00",
         "103.634",
         "100.0",
         "116.424125",
         "116.424125",
         "70.83333333333334",
         "70.83333333333334"
        ],
        [
         "24",
         "Masfout",
         "2023-10-02 00:00:00",
         "102.174",
         "100.0",
         "110.529375",
         "110.529375",
         "100.0",
         "100.0"
        ],
        [
         "25",
         "Masfout",
         "2023-10-02 00:00:00",
         "107.614",
         "100.0",
         "106.317125",
         "106.317125",
         "100.0",
         "100.0"
        ],
        [
         "26",
         "Masfout",
         "2023-10-02 00:00:00",
         "116.052",
         "100.0",
         "105.82587500000001",
         "105.82587500000001",
         "100.0",
         "100.0"
        ],
        [
         "27",
         "Masfout",
         "2023-10-02 00:00:00",
         "120.394",
         "100.0",
         "107.698625",
         "107.698625",
         "100.0",
         "100.0"
        ],
        [
         "28",
         "Masfout",
         "2023-10-02 00:00:00",
         "114.39",
         "100.0",
         "109.641",
         "109.641",
         "100.0",
         "100.0"
        ],
        [
         "29",
         "Masfout",
         "2023-10-02 00:00:00",
         "105.902",
         "100.0",
         "109.959625",
         "109.959625",
         "100.0",
         "100.0"
        ],
        [
         "30",
         "Masfout",
         "2023-10-02 00:00:00",
         "99.793",
         "100.0",
         "108.74412500000001",
         "108.74412500000001",
         "100.0",
         "100.0"
        ],
        [
         "31",
         "Masfout",
         "2023-10-02 00:00:00",
         "137.006",
         "100.0",
         "112.915625",
         "112.915625",
         "100.0",
         "100.0"
        ],
        [
         "32",
         "Masfout",
         "2023-10-02 00:00:00",
         "138.399",
         "100.0",
         "117.44375000000001",
         "117.44375000000001",
         "100.0",
         "100.0"
        ],
        [
         "33",
         "Masfout",
         "2023-10-02 00:00:00",
         "137.206",
         "100.0",
         "121.14275",
         "121.14275",
         "100.0",
         "100.0"
        ],
        [
         "34",
         "Masfout",
         "2023-10-02 00:00:00",
         "137.371",
         "100.0",
         "123.807625",
         "123.807625",
         "100.0",
         "100.0"
        ],
        [
         "35",
         "Masfout",
         "2023-10-02 00:00:00",
         "132.42",
         "100.0",
         "125.310875",
         "125.310875",
         "100.0",
         "100.0"
        ],
        [
         "36",
         "Masfout",
         "2023-10-02 00:00:00",
         "129.622",
         "100.0",
         "127.214875",
         "127.214875",
         "100.0",
         "100.0"
        ],
        [
         "37",
         "Masfout",
         "2023-10-02 00:00:00",
         "124.223",
         "100.0",
         "129.505",
         "129.505",
         "100.0",
         "100.0"
        ],
        [
         "38",
         "Masfout",
         "2023-10-02 00:00:00",
         "122.944",
         "100.0",
         "132.398875",
         "132.398875",
         "100.0",
         "100.0"
        ],
        [
         "39",
         "Masfout",
         "2023-10-02 00:00:00",
         "152.691",
         "100.0",
         "134.3595",
         "134.3595",
         "100.0",
         "100.0"
        ],
        [
         "40",
         "Masfout",
         "2023-10-02 00:00:00",
         "169.292",
         "100.0",
         "138.221125",
         "138.221125",
         "100.0",
         "100.0"
        ],
        [
         "41",
         "Masfout",
         "2023-10-02 00:00:00",
         "166.688",
         "100.0",
         "141.906375",
         "141.906375",
         "100.0",
         "100.0"
        ],
        [
         "42",
         "Masfout",
         "2023-10-02 00:00:00",
         "163.317",
         "100.0",
         "145.14962500000001",
         "145.14962500000001",
         "100.0",
         "100.0"
        ],
        [
         "43",
         "Masfout",
         "2023-10-02 00:00:00",
         "156.42",
         "100.0",
         "148.149625",
         "148.149625",
         "100.0",
         "100.0"
        ],
        [
         "44",
         "Masfout",
         "2023-10-02 00:00:00",
         "145.257",
         "100.0",
         "150.104",
         "150.104",
         "100.0",
         "100.0"
        ],
        [
         "45",
         "Masfout",
         "2023-10-02 00:00:00",
         "143.271",
         "100.0",
         "152.48499999999999",
         "152.48499999999999",
         "100.0",
         "100.0"
        ],
        [
         "46",
         "Masfout",
         "2023-10-02 00:00:00",
         "134.819",
         "100.0",
         "153.96937499999999",
         "153.96937499999999",
         "100.0",
         "100.0"
        ],
        [
         "47",
         "Masfout",
         "2023-10-02 00:00:00",
         "131.243",
         "100.0",
         "151.28837499999997",
         "151.28837499999997",
         "100.0",
         "100.0"
        ],
        [
         "48",
         "Masfout",
         "2023-10-03 00:00:00",
         "121.192",
         "100.0",
         "145.27587499999998",
         "145.27587499999998",
         "100.0",
         "100.0"
        ],
        [
         "49",
         "Masfout",
         "2023-10-03 00:00:00",
         "116.438",
         "100.0",
         "138.99462499999998",
         "138.99462499999998",
         "100.0",
         "100.0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 43822
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>O3</th>\n",
       "      <th>datacap</th>\n",
       "      <th>8h_Avg_WHO</th>\n",
       "      <th>8h_Avg_NS</th>\n",
       "      <th>8h_Avg_WHO_DC</th>\n",
       "      <th>8h_Avg_NS_DC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masfout</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>108.304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>70.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masfout</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>111.036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>70.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Masfout</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>113.208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>70.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masfout</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>114.394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>70.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masfout</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>107.518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>70.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43817</th>\n",
       "      <td>Jurf</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>70.891</td>\n",
       "      <td>100.0</td>\n",
       "      <td>89.561250</td>\n",
       "      <td>89.561250</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43818</th>\n",
       "      <td>Jurf</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>52.967</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.852500</td>\n",
       "      <td>85.852500</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43819</th>\n",
       "      <td>Jurf</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>95.954</td>\n",
       "      <td>100.0</td>\n",
       "      <td>87.591250</td>\n",
       "      <td>87.591250</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43820</th>\n",
       "      <td>Jurf</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>51.156</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.686875</td>\n",
       "      <td>82.686875</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43821</th>\n",
       "      <td>Jurf</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>58.804</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.742000</td>\n",
       "      <td>76.742000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43822 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Station Name       Date       O3  datacap  8h_Avg_WHO  8h_Avg_NS  \\\n",
       "0          Masfout 2023-10-01  108.304      NaN         NaN        NaN   \n",
       "1          Masfout 2023-10-01  111.036      NaN         NaN        NaN   \n",
       "2          Masfout 2023-10-01  113.208      NaN         NaN        NaN   \n",
       "3          Masfout 2023-10-01  114.394      NaN         NaN        NaN   \n",
       "4          Masfout 2023-10-01  107.518      NaN         NaN        NaN   \n",
       "...            ...        ...      ...      ...         ...        ...   \n",
       "43817         Jurf 2023-07-31   70.891    100.0   89.561250  89.561250   \n",
       "43818         Jurf 2023-07-31   52.967    100.0   85.852500  85.852500   \n",
       "43819         Jurf 2023-07-31   95.954    100.0   87.591250  87.591250   \n",
       "43820         Jurf 2023-07-31   51.156    100.0   82.686875  82.686875   \n",
       "43821         Jurf 2023-07-31   58.804    100.0   76.742000  76.742000   \n",
       "\n",
       "       8h_Avg_WHO_DC  8h_Avg_NS_DC  \n",
       "0          70.833333     70.833333  \n",
       "1          70.833333     70.833333  \n",
       "2          70.833333     70.833333  \n",
       "3          70.833333     70.833333  \n",
       "4          70.833333     70.833333  \n",
       "...              ...           ...  \n",
       "43817     100.000000    100.000000  \n",
       "43818     100.000000    100.000000  \n",
       "43819     100.000000    100.000000  \n",
       "43820     100.000000    100.000000  \n",
       "43821     100.000000    100.000000  \n",
       "\n",
       "[43822 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure only the last row of each day for each station retains the values, setting others to NaN\n",
    "df2.loc[df2.duplicated(subset=['Station Name', 'Date'], keep='last'), ['8h_Avg_WHO_DC', '8h_Avg_NS_DC']] = None\n",
    "\n",
    "# Group by 'Station Name' and 'Date'\n",
    "grouped = df2.groupby(['Station Name', 'Date'])\n",
    "\n",
    "# Create new columns for the calculated daily averages\n",
    "df2['Daily_Avg_8h_WHO'] = None\n",
    "df2['Daily_Avg_8h_NS'] = None\n",
    "\n",
    "# Iterate over each group to calculate the averages where count > 75\n",
    "for (station, date), group in grouped:\n",
    "    if group['8h_Avg_WHO_DC'].sum() > 75:  # Check if total count > 75 for WHO\n",
    "        avg_value_who = group['8h_Avg_WHO'].mean()  # Calculate average for WHO\n",
    "        df2.loc[group.index[-1], 'Daily_Avg_8h_WHO'] = avg_value_who  # Assign to last row\n",
    "    \n",
    "    if group['8h_Avg_NS_DC'].sum() > 75:  # Check if total count > 75 for NS\n",
    "        avg_value_ns = group['8h_Avg_NS'].mean()  # Calculate average for NS\n",
    "        df2.loc[group.index[-1], 'Daily_Avg_8h_NS'] = avg_value_ns  # Assign to last row\n",
    "\n",
    "\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], dayfirst=True)\n",
    "\n",
    "# Change date format to ddmmyyyy\n",
    "df2['Date'] = df2['Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Add a new column 'vlookup' that takes the first 5 letters of 'Station Name' and concatenates it with 'Date'\n",
    "df2['vlookup'] = df2['Station Name'].str[:5] + df2['Date'].str.replace('/', '')\n",
    "\n",
    "# Remove the 'Station Name' column\n",
    "df2.drop(columns=['Station Name','Date'], inplace=True)\n",
    "\n",
    "\n",
    "last_rows_per_date_station = df2.drop_duplicates(subset=['vlookup'], keep='last')\n",
    "\n",
    "last_rows_per_date_station = last_rows_per_date_station[['vlookup'] + [col for col in last_rows_per_date_station.columns if col != 'vlookup']]\n",
    "\n",
    "# Reset the index\n",
    "last_rows_per_date_station.reset_index(drop=True, inplace=True)\n",
    "\n",
    "last_rows_per_date_station\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vlookup</th>\n",
       "      <th>CO</th>\n",
       "      <th>datacap</th>\n",
       "      <th>C0_8h_Avg</th>\n",
       "      <th>C0_8h_Avg_DC</th>\n",
       "      <th>Daily_Avg_8h_C0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masfo01102023</td>\n",
       "      <td>0.23</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.20125</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masfo02102023</td>\n",
       "      <td>0.21</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.20250</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.181667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Masfo03102023</td>\n",
       "      <td>0.19</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.194583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masfo04102023</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.17375</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.183073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masfo05102023</td>\n",
       "      <td>0.41</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.183958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>Jurf27072023</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.25125</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.192083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>Jurf28072023</td>\n",
       "      <td>0.31</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.26125</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.185625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>Jurf29072023</td>\n",
       "      <td>0.22</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.26875</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.216042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>Jurf30072023</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.37875</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.267396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Jurf31072023</td>\n",
       "      <td>0.52</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.46625</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.366302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            vlookup    CO  datacap  C0_8h_Avg  C0_8h_Avg_DC Daily_Avg_8h_C0\n",
       "0     Masfo01102023  0.23    100.0    0.20125     70.833333            None\n",
       "1     Masfo02102023  0.21    100.0    0.20250    100.000000        0.181667\n",
       "2     Masfo03102023  0.19    100.0    0.17000    100.000000        0.194583\n",
       "3     Masfo04102023  0.20    100.0    0.17375    100.000000        0.183073\n",
       "4     Masfo05102023  0.41    100.0    0.27000    100.000000        0.183958\n",
       "...             ...   ...      ...        ...           ...             ...\n",
       "1821   Jurf27072023  0.20    100.0    0.25125    100.000000        0.192083\n",
       "1822   Jurf28072023  0.31    100.0    0.26125    100.000000        0.185625\n",
       "1823   Jurf29072023  0.22    100.0    0.26875    100.000000        0.216042\n",
       "1824   Jurf30072023  0.20    100.0    0.37875    100.000000        0.267396\n",
       "1825   Jurf31072023  0.52    100.0    0.46625    100.000000        0.366302\n",
       "\n",
       "[1826 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "selected_columns = df[['Station Name', 'Date', 'CO']]\n",
    "\n",
    "df=selected_columns\n",
    "\n",
    "# Convert 'Date' column to datetime format for proper processing\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "\n",
    "# Extract unique station names\n",
    "unique_station_names = df[\"Station Name\"].unique()\n",
    "\n",
    "# Define the process_data function for CO transformation\n",
    "def process_data(values, dates):\n",
    "    # Create DataFrame\n",
    "    df_temp = pd.DataFrame({'Index': range(len(values)), 'CO': values, 'Date': dates})\n",
    "\n",
    "    # Calculate 8-hour moving average\n",
    "    df_temp['C0_8h_Avg'] = df_temp['CO'].rolling(window=8).mean()\n",
    "\n",
    "    # Calculate datacap (percentage of available data in 8-hour window)\n",
    "    df_temp['datacap'] = df_temp['CO'].rolling(window=8).count() / 8 * 100\n",
    "\n",
    "    # Ensure first 7 values of 'datacap' are blank (NaN)\n",
    "    df_temp.loc[:6, 'datacap'] = None\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "# Process data for each station name\n",
    "dfs = []\n",
    "for station in unique_station_names:\n",
    "    station_data = df[df['Station Name'] == station]\n",
    "    station_values = station_data[\"CO\"].tolist()\n",
    "    station_dates = station_data[\"Date\"].tolist()\n",
    "    processed_df = process_data(station_values, station_dates)\n",
    "    processed_df['Station Name'] = station\n",
    "    dfs.append(processed_df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df2 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rearrange the columns as specified\n",
    "df2 = df2[['Station Name', 'Date', 'CO', 'datacap', 'C0_8h_Avg']]\n",
    "\n",
    "# Calculate C0_8h_Avg_DC (daily data capture percentage for CO 8h Avg)\n",
    "df2['C0_8h_Avg_DC'] = df2.groupby(['Station Name', 'Date'])['C0_8h_Avg'].transform(lambda x: x.count() / 24 * 100)\n",
    "\n",
    "# Ensure only the last row of each day for each station retains the values, setting others to NaN\n",
    "df2.loc[df2.duplicated(subset=['Station Name', 'Date'], keep='last'), ['C0_8h_Avg_DC']] = None\n",
    "\n",
    "# Group by 'Station Name' and 'Date'\n",
    "grouped = df2.groupby(['Station Name', 'Date'])\n",
    "\n",
    "# Create new columns for the calculated daily averages\n",
    "df2['Daily_Avg_8h_C0'] = None\n",
    "\n",
    "# Iterate over each group to calculate the daily averages where count > 75\n",
    "for (station, date), group in grouped:\n",
    "    if group['C0_8h_Avg_DC'].sum() > 75:  # Check if total count > 75\n",
    "        avg_value_c0 = group['C0_8h_Avg'].mean()  # Calculate average\n",
    "        df2.loc[group.index[-1], 'Daily_Avg_8h_C0'] = avg_value_c0  # Assign to last row\n",
    "\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], dayfirst=True)\n",
    "\n",
    "# Change date format to ddmmyyyy\n",
    "df2['Date'] = df2['Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Add a new column 'vlookup' that takes the first 5 letters of 'Station Name' and concatenates it with 'Date'\n",
    "df2['vlookup'] = df2['Station Name'].str[:5] + df2['Date'].str.replace('/', '')\n",
    "\n",
    "# Remove the 'Station Name' column\n",
    "df2.drop(columns=['Station Name','Date'], inplace=True)\n",
    "\n",
    "\n",
    "last_rows_per_date_station2 = df2.drop_duplicates(subset=['vlookup'], keep='last')\n",
    "\n",
    "last_rows_per_date_station2 = last_rows_per_date_station2[['vlookup'] + [col for col in last_rows_per_date_station2.columns if col != 'vlookup']]\n",
    "\n",
    "# Reset the index\n",
    "last_rows_per_date_station2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "last_rows_per_date_station2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Merge last_rows_per_date_station and last_rows_per_date_station2 on 'vlookup'\n",
    "combined_df = pd.merge(last_rows_per_date_station, last_rows_per_date_station2, on='vlookup', suffixes=('_O3', '_CO'))\n",
    "\n",
    "# Merge the result with final_df on 'vlookup'\n",
    "combined_df = pd.merge(combined_df, final_df, on='vlookup')\n",
    "\n",
    "# Display the combined dataframe\n",
    "D24hparameter=combined_df[['vlookup','SO2', 'NO2', 'Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0', 'PM10', 'PM2.5']]\n",
    "\n",
    "D24hparameter.to_csv('/workspaces/vikrant_dubai/SQL/D24hparameter.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Round all columns of D24hparameter to 1 decimal place\n",
    "D24hparameter_rounded = D24hparameter.round(1)\n",
    "# Convert 'Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', and 'Daily_Avg_8h_C0' to numeric, forcing errors to NaN\n",
    "D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']] = D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Round the specified columns to 1 decimal place\n",
    "D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']] = D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']].round(1)\n",
    "# Display the new table\n",
    "D24hparameter_rounded.to_csv('/workspaces/vikrant_dubai/SQL/D24hparameter_rounded.csv', index=False)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df=D24hparameter_rounded\n",
    "\n",
    "# Create a new DataFrame KPI_NS containing only the 'vlookup' column\n",
    "KPI_NS = df[['vlookup']].copy()\n",
    "\n",
    "# Add 'SO2' column based on the condition\n",
    "KPI_NS['SO2'] = df['SO2'].apply(lambda x: 1 if x < 150.4 else 0)\n",
    "\n",
    "# Add 'NO2' column based on the condition\n",
    "KPI_NS['NO2'] = df['NO2'].apply(lambda x: 1 if x < 150.4 else 0)\n",
    "\n",
    "# Add 'O3' column based on the condition using 'Daily_Avg_8h_NS'\n",
    "KPI_NS['O3'] = df['Daily_Avg_8h_NS'].apply(lambda x: 1 if x < 120.4 else 0)\n",
    "\n",
    "# Add 'CO' column based on the condition using 'Daily_Avg_8h_C0'\n",
    "KPI_NS['CO'] = df['Daily_Avg_8h_C0'].apply(lambda x: 1 if x < 10.4 else 0)\n",
    "\n",
    "\n",
    "KPI_NS.to_csv('/workspaces/vikrant_dubai/SQL/KPI_NS.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "df=D24hparameter_rounded\n",
    "\n",
    "# Create a new DataFrame KPI_NS containing only the 'vlookup' column\n",
    "KPI_WHO = df[['vlookup']].copy()\n",
    "\n",
    "# Add 'SO2' column based on the condition\n",
    "KPI_WHO['SO2'] = df['SO2'].apply(lambda x: 1 if x < 20.4 else 0)\n",
    "\n",
    "# Add 'NO2' column based on the condition\n",
    "KPI_WHO['NO2'] = df['NO2'].apply(lambda x: 1 if x < 75.4 else 0)\n",
    "\n",
    "# Add 'O3' column based on the condition using 'Daily_Avg_8h_NS'\n",
    "KPI_WHO['O3'] = df['Daily_Avg_8h_NS'].apply(lambda x: 1 if x < 100.4 else 0)\n",
    "\n",
    "# Add 'CO' column based on the condition using 'Daily_Avg_8h_C0'\n",
    "KPI_WHO['CO'] = df['Daily_Avg_8h_C0'].apply(lambda x: 1 if x < 10.4 else 0)\n",
    "\n",
    "\n",
    "KPI_WHO.to_csv('/workspaces/vikrant_dubai/SQL/KPI_WHO.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "KPI_PM = df[['vlookup']].copy()\n",
    "KPI_PM['PM10'] = df['PM10'].apply(lambda x: 1 if x < 150.4 else 0)\n",
    "KPI_PM['PM2.5'] = df['PM2.5'].apply(lambda x: 1 if x < 60.4 else 0)\n",
    "KPI_PM.to_csv('/workspaces/vikrant_dubai/SQL/KPI_PM.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
