{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20163/1962484940.py:1: DtypeWarning: Columns (6,9,15,23,27,29,39,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/workspaces/vikrant_dubai/final/comb/AJ_combined.csv')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('/workspaces/vikrant_dubai/final/comb/AJ_combined.csv')\n",
    "unique_station_names = df['Station Name'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Masfout', 'Envi', 'AjmanX', 'Manama', 'Jurf'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_station_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finder_table(df):\n",
    "    df['vlookup'] = df['Station Name'].str[:3] + df['Date'].str.replace('/', '')\n",
    "    df_grouped = df.groupby(['Station Name', 'Date']).first().reset_index()\n",
    "    df_grouped['vlookup'] = df_grouped['Station Name'].str[:5] + df_grouped['Date'].str.replace('/', '')\n",
    "    Finder_table = df_grouped[['Station Name', 'Date', 'vlookup']]\n",
    "    return Finder_table\n",
    "\n",
    "# Example usage:\n",
    "Finder_table = create_finder_table(df)\n",
    "Finder_table.to_csv('/workspaces/vikrant_dubai/SQL/Finder_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>vlookup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.908333</td>\n",
       "      <td>28.313750</td>\n",
       "      <td>1.162500</td>\n",
       "      <td>1.059583</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>Ajman01012023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.296667</td>\n",
       "      <td>26.647083</td>\n",
       "      <td>1.319167</td>\n",
       "      <td>23.330833</td>\n",
       "      <td>7.953750</td>\n",
       "      <td>Ajman01022023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.155000</td>\n",
       "      <td>29.250417</td>\n",
       "      <td>0.584583</td>\n",
       "      <td>17.247500</td>\n",
       "      <td>8.151667</td>\n",
       "      <td>Ajman01032023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.024583</td>\n",
       "      <td>17.529167</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>24.255000</td>\n",
       "      <td>9.757917</td>\n",
       "      <td>Ajman01042023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.935417</td>\n",
       "      <td>33.590833</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ajman01052023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>3.886333</td>\n",
       "      <td>4.394500</td>\n",
       "      <td>0.162237</td>\n",
       "      <td>79.647500</td>\n",
       "      <td>33.690417</td>\n",
       "      <td>Masfo31052023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>5.227808</td>\n",
       "      <td>14.374129</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>45.990417</td>\n",
       "      <td>18.035417</td>\n",
       "      <td>Masfo31072023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>6.245158</td>\n",
       "      <td>10.898500</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>43.170833</td>\n",
       "      <td>19.293333</td>\n",
       "      <td>Masfo31082023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>4.120258</td>\n",
       "      <td>17.298975</td>\n",
       "      <td>0.150417</td>\n",
       "      <td>15.979583</td>\n",
       "      <td>6.572917</td>\n",
       "      <td>Masfo31102023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>8.712504</td>\n",
       "      <td>26.662792</td>\n",
       "      <td>0.279583</td>\n",
       "      <td>30.811250</td>\n",
       "      <td>11.532917</td>\n",
       "      <td>Masfo31122023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1825 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SO2        NO2        CO       PM10      PM2.5        vlookup\n",
       "0     1.908333  28.313750  1.162500   1.059583   0.085417  Ajman01012023\n",
       "1     1.296667  26.647083  1.319167  23.330833   7.953750  Ajman01022023\n",
       "2     2.155000  29.250417  0.584583  17.247500   8.151667  Ajman01032023\n",
       "3     2.024583  17.529167  0.818333  24.255000   9.757917  Ajman01042023\n",
       "4     2.935417  33.590833  0.326667        NaN        NaN  Ajman01052023\n",
       "...        ...        ...       ...        ...        ...            ...\n",
       "1820  3.886333   4.394500  0.162237  79.647500  33.690417  Masfo31052023\n",
       "1821  5.227808  14.374129  0.216667  45.990417  18.035417  Masfo31072023\n",
       "1822  6.245158  10.898500  0.202500  43.170833  19.293333  Masfo31082023\n",
       "1823  4.120258  17.298975  0.150417  15.979583   6.572917  Masfo31102023\n",
       "1824  8.712504  26.662792  0.279583  30.811250  11.532917  Masfo31122023\n",
       "\n",
       "[1825 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "pollutants = ['SO2', 'NO2','CO','PM10', 'PM2.5']\n",
    "\n",
    "# Convert pollutant columns to numeric, forcing errors to NaN\n",
    "df[pollutants] = df[pollutants].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "avg_values = df.groupby(['Station Name', 'Date'])[pollutants].mean().reset_index()\n",
    "\n",
    "final_df = pd.merge(avg_values, Finder_table, on=['Station Name', 'Date'], suffixes=(' Avg 24H', ''))\n",
    "final_df.rename(columns={'Station Name': 'Name'}, inplace=True)\n",
    "final_df['vlookup'] = final_df['Name'].str[:5] + final_df['Date'].str.replace('/', '')\n",
    "final_df=final_df.drop(columns=['Name', 'Date'])\n",
    "final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20163/1767192535.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_columns['O3'] = pd.to_numeric(selected_columns['O3'], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vlookup</th>\n",
       "      <th>O3</th>\n",
       "      <th>datacap</th>\n",
       "      <th>8h_Avg_WHO</th>\n",
       "      <th>8h_Avg_NS</th>\n",
       "      <th>8h_Avg_WHO_DC</th>\n",
       "      <th>8h_Avg_NS_DC</th>\n",
       "      <th>Daily_Avg_8h_WHO</th>\n",
       "      <th>Daily_Avg_8h_NS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masfo01102023</td>\n",
       "      <td>103.634</td>\n",
       "      <td>100.0</td>\n",
       "      <td>116.424125</td>\n",
       "      <td>116.424125</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masfo02102023</td>\n",
       "      <td>131.243</td>\n",
       "      <td>100.0</td>\n",
       "      <td>151.288375</td>\n",
       "      <td>151.288375</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>127.670339</td>\n",
       "      <td>127.670339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Masfo03102023</td>\n",
       "      <td>99.109</td>\n",
       "      <td>100.0</td>\n",
       "      <td>137.166250</td>\n",
       "      <td>137.166250</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>137.381469</td>\n",
       "      <td>137.381469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masfo04102023</td>\n",
       "      <td>90.020</td>\n",
       "      <td>100.0</td>\n",
       "      <td>114.016000</td>\n",
       "      <td>114.016000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>103.529687</td>\n",
       "      <td>103.529687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masfo05102023</td>\n",
       "      <td>79.889</td>\n",
       "      <td>100.0</td>\n",
       "      <td>143.905250</td>\n",
       "      <td>143.905250</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>109.367406</td>\n",
       "      <td>109.367406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>Jurf27072023</td>\n",
       "      <td>14.689</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.987500</td>\n",
       "      <td>32.987500</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>34.082521</td>\n",
       "      <td>34.082521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>Jurf28072023</td>\n",
       "      <td>12.497</td>\n",
       "      <td>100.0</td>\n",
       "      <td>34.849500</td>\n",
       "      <td>34.849500</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>33.127177</td>\n",
       "      <td>33.127177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>Jurf29072023</td>\n",
       "      <td>28.375</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.401125</td>\n",
       "      <td>31.401125</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.597365</td>\n",
       "      <td>27.597365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>Jurf30072023</td>\n",
       "      <td>52.963</td>\n",
       "      <td>100.0</td>\n",
       "      <td>44.716500</td>\n",
       "      <td>44.716500</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>37.135146</td>\n",
       "      <td>37.135146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Jurf31072023</td>\n",
       "      <td>58.804</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.742000</td>\n",
       "      <td>76.742000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>53.792286</td>\n",
       "      <td>53.792286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            vlookup       O3  datacap  8h_Avg_WHO   8h_Avg_NS  8h_Avg_WHO_DC  \\\n",
       "0     Masfo01102023  103.634    100.0  116.424125  116.424125      70.833333   \n",
       "1     Masfo02102023  131.243    100.0  151.288375  151.288375     100.000000   \n",
       "2     Masfo03102023   99.109    100.0  137.166250  137.166250     100.000000   \n",
       "3     Masfo04102023   90.020    100.0  114.016000  114.016000     100.000000   \n",
       "4     Masfo05102023   79.889    100.0  143.905250  143.905250     100.000000   \n",
       "...             ...      ...      ...         ...         ...            ...   \n",
       "1821   Jurf27072023   14.689    100.0   32.987500   32.987500     100.000000   \n",
       "1822   Jurf28072023   12.497    100.0   34.849500   34.849500     100.000000   \n",
       "1823   Jurf29072023   28.375    100.0   31.401125   31.401125     100.000000   \n",
       "1824   Jurf30072023   52.963    100.0   44.716500   44.716500     100.000000   \n",
       "1825   Jurf31072023   58.804    100.0   76.742000   76.742000     100.000000   \n",
       "\n",
       "      8h_Avg_NS_DC Daily_Avg_8h_WHO Daily_Avg_8h_NS  \n",
       "0        70.833333             None            None  \n",
       "1       100.000000       127.670339      127.670339  \n",
       "2       100.000000       137.381469      137.381469  \n",
       "3       100.000000       103.529687      103.529687  \n",
       "4       100.000000       109.367406      109.367406  \n",
       "...            ...              ...             ...  \n",
       "1821    100.000000        34.082521       34.082521  \n",
       "1822    100.000000        33.127177       33.127177  \n",
       "1823    100.000000        27.597365       27.597365  \n",
       "1824    100.000000        37.135146       37.135146  \n",
       "1825    100.000000        53.792286       53.792286  \n",
       "\n",
       "[1826 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "selected_columns = df[['Station Name', 'Date', 'O3']]\n",
    "\n",
    "# Convert 'O3' column to numeric type\n",
    "selected_columns['O3'] = pd.to_numeric(selected_columns['O3'], errors='coerce')\n",
    "\n",
    "\n",
    "# Extract unique station names\n",
    "unique_station_names = selected_columns[\"Station Name\"].unique()\n",
    "\n",
    "# Define the process_data function\n",
    "def process_data(values, dates):\n",
    "    # Create DataFrame\n",
    "    df_temp = pd.DataFrame({'Index': range(len(values)), 'Values': values, 'Date': dates})\n",
    "\n",
    "    # Calculate 8-hour moving average\n",
    "    df_temp['8h_Avg'] = df_temp['Values'].rolling(window=8).mean()\n",
    "\n",
    "    # Calculate datacap (percentage of available data in 8-hour window)\n",
    "    df_temp['datacap'] = df_temp['Values'].rolling(window=8).count() / 8 * 100\n",
    "\n",
    "    # Ensure first 7 values of 'datacap' are blank (NaN)\n",
    "    df_temp.loc[:6, 'datacap'] = None\n",
    "\n",
    "    # Define function to calculate 8h_Avg_WHO and 8h_Avg_NS\n",
    "    def calculate_adjusted_avg(df_temp, max_threshold):\n",
    "        adjusted_avg = [None] * len(df_temp)\n",
    "        for i in range(7, len(df_temp)):\n",
    "            if df_temp.loc[i, 'datacap'] > 75:\n",
    "                adjusted_avg[i] = df_temp.loc[i, '8h_Avg']\n",
    "            else:\n",
    "                max_value = df_temp.loc[i-7:i, 'Values'].max()\n",
    "                if max_value > max_threshold:\n",
    "                    adjusted_avg[i] = max_value\n",
    "        return adjusted_avg\n",
    "\n",
    "    # Calculate 8h_Avg_WHO with max value threshold of 100\n",
    "    df_temp['8h_Avg_WHO'] = calculate_adjusted_avg(df_temp, 100)\n",
    "\n",
    "    # Calculate 8h_Avg_NS with max value threshold of 120\n",
    "    df_temp['8h_Avg_NS'] = calculate_adjusted_avg(df_temp, 120)\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "# Process data for each station name\n",
    "dfs = []\n",
    "for station in unique_station_names:\n",
    "    station_data = selected_columns[selected_columns['Station Name'] == station]\n",
    "    station_values = station_data[\"O3\"].tolist()\n",
    "    station_dates = station_data[\"Date\"].tolist()\n",
    "    processed_df = process_data(station_values, station_dates)\n",
    "    processed_df['Station Name'] = station\n",
    "    dfs.append(processed_df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df2 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rearrange the columns as specified\n",
    "df2 = df2[['Station Name', 'Date', 'Values', 'datacap', '8h_Avg_WHO', '8h_Avg_NS']]\n",
    "df2.rename(columns={'Values': 'O3'}, inplace=True)\n",
    "\n",
    "# Convert 'Date' column to datetime format for proper grouping\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], dayfirst=True)\n",
    "\n",
    "# Calculate 8h_Avg_WHO_DC and 8h_Avg_NS_DC\n",
    "df2['8h_Avg_WHO_DC'] = df2.groupby(['Station Name', 'Date'])['8h_Avg_WHO'].transform(lambda x: x.count() / 24 * 100)\n",
    "df2['8h_Avg_NS_DC'] = df2.groupby(['Station Name', 'Date'])['8h_Avg_NS'].transform(lambda x: x.count() / 24 * 100)\n",
    "\n",
    "# Ensure only the last row of each day for each station retains the values, setting others to NaN\n",
    "df2.loc[df2.duplicated(subset=['Station Name', 'Date'], keep='last'), ['8h_Avg_WHO_DC', '8h_Avg_NS_DC']] = None\n",
    "\n",
    "# Group by 'Station Name' and 'Date'\n",
    "grouped = df2.groupby(['Station Name', 'Date'])\n",
    "\n",
    "# Create new columns for the calculated daily averages\n",
    "df2['Daily_Avg_8h_WHO'] = None\n",
    "df2['Daily_Avg_8h_NS'] = None\n",
    "\n",
    "# Iterate over each group to calculate the averages where count > 75\n",
    "for (station, date), group in grouped:\n",
    "    if group['8h_Avg_WHO_DC'].sum() > 75:  # Check if total count > 75 for WHO\n",
    "        avg_value_who = group['8h_Avg_WHO'].mean()  # Calculate average for WHO\n",
    "        df2.loc[group.index[-1], 'Daily_Avg_8h_WHO'] = avg_value_who  # Assign to last row\n",
    "    \n",
    "    if group['8h_Avg_NS_DC'].sum() > 75:  # Check if total count > 75 for NS\n",
    "        avg_value_ns = group['8h_Avg_NS'].mean()  # Calculate average for NS\n",
    "        df2.loc[group.index[-1], 'Daily_Avg_8h_NS'] = avg_value_ns  # Assign to last row\n",
    "\n",
    "\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], dayfirst=True)\n",
    "\n",
    "# Change date format to ddmmyyyy\n",
    "df2['Date'] = df2['Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Add a new column 'vlookup' that takes the first 5 letters of 'Station Name' and concatenates it with 'Date'\n",
    "df2['vlookup'] = df2['Station Name'].str[:5] + df2['Date'].str.replace('/', '')\n",
    "\n",
    "# Remove the 'Station Name' column\n",
    "df2.drop(columns=['Station Name','Date'], inplace=True)\n",
    "\n",
    "\n",
    "last_rows_per_date_station = df2.drop_duplicates(subset=['vlookup'], keep='last')\n",
    "\n",
    "last_rows_per_date_station = last_rows_per_date_station[['vlookup'] + [col for col in last_rows_per_date_station.columns if col != 'vlookup']]\n",
    "\n",
    "# Reset the index\n",
    "last_rows_per_date_station.reset_index(drop=True, inplace=True)\n",
    "\n",
    "last_rows_per_date_station\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "selected_columns = df[['Station Name', 'Date', 'CO']]\n",
    "\n",
    "df=selected_columns\n",
    "\n",
    "# Convert 'Date' column to datetime format for proper processing\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "\n",
    "# Extract unique station names\n",
    "unique_station_names = df[\"Station Name\"].unique()\n",
    "\n",
    "# Define the process_data function for CO transformation\n",
    "def process_data(values, dates):\n",
    "    # Create DataFrame\n",
    "    df_temp = pd.DataFrame({'Index': range(len(values)), 'CO': values, 'Date': dates})\n",
    "\n",
    "    # Calculate 8-hour moving average\n",
    "    df_temp['C0_8h_Avg'] = df_temp['CO'].rolling(window=8).mean()\n",
    "\n",
    "    # Calculate datacap (percentage of available data in 8-hour window)\n",
    "    df_temp['datacap'] = df_temp['CO'].rolling(window=8).count() / 8 * 100\n",
    "\n",
    "    # Ensure first 7 values of 'datacap' are blank (NaN)\n",
    "    df_temp.loc[:6, 'datacap'] = None\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "# Process data for each station name\n",
    "dfs = []\n",
    "for station in unique_station_names:\n",
    "    station_data = df[df['Station Name'] == station]\n",
    "    station_values = station_data[\"CO\"].tolist()\n",
    "    station_dates = station_data[\"Date\"].tolist()\n",
    "    processed_df = process_data(station_values, station_dates)\n",
    "    processed_df['Station Name'] = station\n",
    "    dfs.append(processed_df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df2 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rearrange the columns as specified\n",
    "df2 = df2[['Station Name', 'Date', 'CO', 'datacap', 'C0_8h_Avg']]\n",
    "\n",
    "# Calculate C0_8h_Avg_DC (daily data capture percentage for CO 8h Avg)\n",
    "df2['C0_8h_Avg_DC'] = df2.groupby(['Station Name', 'Date'])['C0_8h_Avg'].transform(lambda x: x.count() / 24 * 100)\n",
    "\n",
    "# Ensure only the last row of each day for each station retains the values, setting others to NaN\n",
    "df2.loc[df2.duplicated(subset=['Station Name', 'Date'], keep='last'), ['C0_8h_Avg_DC']] = None\n",
    "\n",
    "# Group by 'Station Name' and 'Date'\n",
    "grouped = df2.groupby(['Station Name', 'Date'])\n",
    "\n",
    "# Create new columns for the calculated daily averages\n",
    "df2['Daily_Avg_8h_C0'] = None\n",
    "\n",
    "# Iterate over each group to calculate the daily averages where count > 75\n",
    "for (station, date), group in grouped:\n",
    "    if group['C0_8h_Avg_DC'].sum() > 75:  # Check if total count > 75\n",
    "        avg_value_c0 = group['C0_8h_Avg'].mean()  # Calculate average\n",
    "        df2.loc[group.index[-1], 'Daily_Avg_8h_C0'] = avg_value_c0  # Assign to last row\n",
    "\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], dayfirst=True)\n",
    "\n",
    "# Change date format to ddmmyyyy\n",
    "df2['Date'] = df2['Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Add a new column 'vlookup' that takes the first 5 letters of 'Station Name' and concatenates it with 'Date'\n",
    "df2['vlookup'] = df2['Station Name'].str[:5] + df2['Date'].str.replace('/', '')\n",
    "\n",
    "# Remove the 'Station Name' column\n",
    "df2.drop(columns=['Station Name','Date'], inplace=True)\n",
    "\n",
    "\n",
    "last_rows_per_date_station2 = df2.drop_duplicates(subset=['vlookup'], keep='last')\n",
    "\n",
    "last_rows_per_date_station2 = last_rows_per_date_station2[['vlookup'] + [col for col in last_rows_per_date_station2.columns if col != 'vlookup']]\n",
    "\n",
    "# Reset the index\n",
    "last_rows_per_date_station2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "last_rows_per_date_station2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Merge last_rows_per_date_station and last_rows_per_date_station2 on 'vlookup'\n",
    "combined_df = pd.merge(last_rows_per_date_station, last_rows_per_date_station2, on='vlookup', suffixes=('_O3', '_CO'))\n",
    "\n",
    "# Merge the result with final_df on 'vlookup'\n",
    "combined_df = pd.merge(combined_df, final_df, on='vlookup')\n",
    "\n",
    "# Display the combined dataframe\n",
    "D24hparameter=combined_df[['vlookup','SO2', 'NO2', 'Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0', 'PM10', 'PM2.5']]\n",
    "\n",
    "D24hparameter.to_csv('/workspaces/vikrant_dubai/SQL/D24hparameter.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Round all columns of D24hparameter to 1 decimal place\n",
    "D24hparameter_rounded = D24hparameter.round(1)\n",
    "# Convert 'Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', and 'Daily_Avg_8h_C0' to numeric, forcing errors to NaN\n",
    "D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']] = D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Round the specified columns to 1 decimal place\n",
    "D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']] = D24hparameter_rounded[['Daily_Avg_8h_WHO', 'Daily_Avg_8h_NS', 'Daily_Avg_8h_C0']].round(1)\n",
    "# Display the new table\n",
    "D24hparameter_rounded.to_csv('/workspaces/vikrant_dubai/SQL/D24hparameter_rounded.csv', index=False)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df=D24hparameter_rounded\n",
    "\n",
    "# Create a new DataFrame KPI_NS containing only the 'vlookup' column\n",
    "KPI_NS = df[['vlookup']].copy()\n",
    "\n",
    "# Add 'SO2' column based on the condition\n",
    "KPI_NS['SO2'] = df['SO2'].apply(lambda x: 1 if x < 150.4 else 0)\n",
    "\n",
    "# Add 'NO2' column based on the condition\n",
    "KPI_NS['NO2'] = df['NO2'].apply(lambda x: 1 if x < 150.4 else 0)\n",
    "\n",
    "# Add 'O3' column based on the condition using 'Daily_Avg_8h_NS'\n",
    "KPI_NS['O3'] = df['Daily_Avg_8h_NS'].apply(lambda x: 1 if x < 120.4 else 0)\n",
    "\n",
    "# Add 'CO' column based on the condition using 'Daily_Avg_8h_C0'\n",
    "KPI_NS['CO'] = df['Daily_Avg_8h_C0'].apply(lambda x: 1 if x < 10.4 else 0)\n",
    "\n",
    "\n",
    "KPI_NS.to_csv('/workspaces/vikrant_dubai/SQL/KPI_NS.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "df=D24hparameter_rounded\n",
    "\n",
    "# Create a new DataFrame KPI_NS containing only the 'vlookup' column\n",
    "KPI_WHO = df[['vlookup']].copy()\n",
    "\n",
    "# Add 'SO2' column based on the condition\n",
    "KPI_WHO['SO2'] = df['SO2'].apply(lambda x: 1 if x < 20.4 else 0)\n",
    "\n",
    "# Add 'NO2' column based on the condition\n",
    "KPI_WHO['NO2'] = df['NO2'].apply(lambda x: 1 if x < 75.4 else 0)\n",
    "\n",
    "# Add 'O3' column based on the condition using 'Daily_Avg_8h_NS'\n",
    "KPI_WHO['O3'] = df['Daily_Avg_8h_NS'].apply(lambda x: 1 if x < 100.4 else 0)\n",
    "\n",
    "# Add 'CO' column based on the condition using 'Daily_Avg_8h_C0'\n",
    "KPI_WHO['CO'] = df['Daily_Avg_8h_C0'].apply(lambda x: 1 if x < 10.4 else 0)\n",
    "\n",
    "\n",
    "KPI_WHO.to_csv('/workspaces/vikrant_dubai/SQL/KPI_WHO.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "KPI_PM = df[['vlookup']].copy()\n",
    "KPI_PM['PM10'] = df['PM10'].apply(lambda x: 1 if x < 150.4 else 0)\n",
    "KPI_PM['PM2.5'] = df['PM2.5'].apply(lambda x: 1 if x < 60.4 else 0)\n",
    "KPI_PM.to_csv('/workspaces/vikrant_dubai/SQL/KPI_PM.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
