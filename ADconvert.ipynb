{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=9\n",
    "\n",
    "mdf=pd.read_excel(f'/workspaces/vikrant_dubai/RAW/AD/AD {n}.xlsx')\n",
    "excel_file = pd.ExcelFile(f'/workspaces/vikrant_dubai/RAW/AD/AD {n}.xlsx')\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Station Name\", \"Latitude\", \"Longitude\", \"Region\", \"Area Classification\"])\n",
    "dfs = []\n",
    "for i in range(len(excel_file.sheet_names)-4):\n",
    "    df = pd.read_excel(f\"/workspaces/vikrant_dubai/RAW/AD/AD {n}.xlsx\", sheet_name = excel_file.sheet_names[i])\n",
    "    df2 = df.iloc[:, :8]\n",
    "\n",
    "    df = df2.transpose().iloc[:, :1]\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "\n",
    "    mapped_data = {\n",
    "        \"Station Name\": df.index[0],  \n",
    "        \"Latitude\": df.iloc[1, 0],  \n",
    "        \"Longitude\": df.iloc[3, 0],  \n",
    "        \"Region\": df.index[3],  \n",
    "        \"Area Classification\": df.index[6]  \n",
    "    }\n",
    "    temp_df = pd.DataFrame([mapped_data])\n",
    "    dfs.append(temp_df)\n",
    "\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "# final_df.to_csv(f'/workspaces/vikrant_dubai/final/details{k}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date/Time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:191\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:234\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:242\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:134\u001b[0m, in \u001b[0;36mpandas._libs.index._unpack_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date/Time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m mdf \u001b[38;5;241m=\u001b[39m mdf[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert 'Date/Time' column to separate 'Date' and 'Time' columns\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate/Time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mmdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate/Time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     13\u001b[0m mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate/Time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[1;32m     14\u001b[0m mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate/Time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtime\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date/Time'"
     ]
    }
   ],
   "source": [
    "columns_of_main_df = ['Station Name','Date', 'Time', 'SO2', 'Data Cap. (SO2)', 'SO2 Avg', 'NO2', 'Data Cap. (NO2)', 'NO2 Avg',      'O3', 'Data Cap. (O3)', 'O3 8H Avg.', 'Daily Capture O3', 'O3 Daily Average', 'O3 Daily Average (NS)', 'CO',  'Data Cap. (CO)', 'CO 8H Avg.', 'Daily Capture CO', 'CO Daily Average', 'PM10',    'Data Cap. (PM10)', 'PM10 Avg', 'PM2.5', 'Data Cap. (PM2.5)', 'PM2.5 Avg', 'Lower Ambient Temperature', 'Upper Ambient Temperature', 'Barometric Pressure', 'Relative Humidity', 'Wind Direction', 'Wind Speed', 'H2S', 'Toluene', 'O-Xylene', 'Ethylbenzene', 'MP-Xylene', 'Benzene', 'CH4', 'NMHC', 'THC', 'Noise', 'Solar Radiation',]\n",
    "for s in range(len(excel_file.sheet_names)-4):\n",
    "    main_df = pd.DataFrame(columns=columns_of_main_df)\n",
    "\n",
    "    # Read the Excel file and preprocess the data\n",
    "    mdf = pd.read_excel(f'/workspaces/vikrant_dubai/RAW/AD/AD {n}.xlsx', sheet_name=excel_file.sheet_names[s])\n",
    "    mdf = mdf.drop([0, 1, 2, 3]).reset_index(drop=True)\n",
    "    mdf.columns = mdf.iloc[0]\n",
    "    mdf = mdf[1:].reset_index(drop=True).drop([0, 1]).reset_index(drop=True)\n",
    "\n",
    "    # Convert 'Date/Time' column to separate 'Date' and 'Time' columns\n",
    "    mdf['Date/Time'] = pd.to_datetime(mdf['Date/Time'])\n",
    "    mdf['Date'] = mdf['Date/Time'].dt.date\n",
    "    mdf['Time'] = mdf['Date/Time'].dt.time\n",
    "\n",
    "    # Iterate over the series and replace the column names\n",
    "    new_df_columns = mdf.columns.tolist()\n",
    "    for col_index in range(1, len(new_df_columns)):\n",
    "        if 'DATA CAP.' in new_df_columns[col_index]:\n",
    "            if new_df_columns[col_index-1] == 'DATA COUNT':\n",
    "                new_df_columns[col_index] = f\"DATA CAP. ({new_df_columns[col_index-2]})\"\n",
    "            else:\n",
    "                new_df_columns[col_index] = f\"DATA CAP. ({new_df_columns[col_index-1]})\"\n",
    "        if 'Daily Capture' in new_df_columns[col_index]:\n",
    "            new_df_columns[col_index] = f\"Daily Capture {new_df_columns[col_index-1]}\"\n",
    "            if '8H Avg.' in new_df_columns[col_index-1]:\n",
    "                new_df_columns[col_index] = new_df_columns[col_index].replace('8H Avg.', '')\n",
    "    mdf.columns = new_df_columns\n",
    "\n",
    "    # Reorder columns and drop the original 'Date/Time' column\n",
    "    mdf = mdf[['Date', 'Time'] + [col for col in mdf.columns if col not in ['Date', 'Time']]]\n",
    "    mdf = mdf.drop(columns=['Date/Time'])\n",
    "\n",
    "    # add column station name\n",
    "    mdf['Station Name'] = excel_file.sheet_names[s]\n",
    "\n",
    "    # Format the 'Date' column\n",
    "    mdf['Date'] = pd.to_datetime(mdf['Date']).dt.strftime('%d/%m/%Y')\n",
    "\n",
    "    main_df['Station Name'] = mdf['Station Name']\n",
    "    main_df['Date'] = mdf['Date']\n",
    "    main_df['Time'] = mdf['Time']\n",
    "    main_df[\"SO2\"]=mdf[\"SO2\"]\n",
    "    main_df[\"Data Cap. (SO2)\"]=mdf[\"DATA CAP. (SO2)\"]\n",
    "    main_df[\"SO2 Avg\"]=mdf[\"SO2 Avg\"]\n",
    "    main_df[\"NO2\"]=mdf[\"NO2\"]\n",
    "    main_df[\"Data Cap. (NO2)\"]=mdf[\"DATA CAP. (NO2)\"]\n",
    "    main_df[\"NO2 Avg\"]=mdf[\"No2 Avg\"]\n",
    "    main_df[\"O3\"]=mdf[\"O3\"]\n",
    "    main_df[\"Data Cap. (O3)\"]=mdf[\"DATA CAP. (O3)\"]\n",
    "    main_df[\"O3 8H Avg.\"]=mdf[\"O3 8H Avg.\"]\n",
    "    main_df[\"Daily Capture O3\"]=mdf[\"Daily Capture O3 \"]\n",
    "    main_df[\"O3 Daily Average\"]=mdf[\"O3 Daily average\"]\n",
    "    main_df[\"O3 Daily Average (NS)\"]=mdf[\"O3 Daily average (NS)\"]\n",
    "    main_df[\"CO\"]=mdf[\"CO\"]\n",
    "    main_df[\"Data Cap. (CO)\"]=mdf[\"DATA CAP. (CO)\"]\n",
    "    main_df[\"CO 8H Avg.\"]=mdf[\"CO 8H Avg.\"]\n",
    "    main_df[\"Daily Capture CO\"]=mdf[\"Daily Capture CO \"]\n",
    "    main_df[\"CO Daily Average\"]=mdf[\"CO Daily average\"]\n",
    "    main_df[\"PM10\"]=mdf[\"PM10\"]\n",
    "    main_df[\"Data Cap. (PM10)\"]=mdf[\"DATA CAP. (PM10)\"]\n",
    "    main_df[\"PM10 Avg\"]=mdf[\"PM10 Avg\"]\n",
    "    main_df[\"PM2.5\"]=mdf[\"PM2.5\"]\n",
    "    main_df[\"Data Cap. (PM2.5)\"]=mdf[\"DATA CAP. (PM2.5)\"]\n",
    "    main_df[\"PM2.5 Avg\"]=mdf[\"PM2.5 Avg\"]\n",
    "    main_df[\"Lower Ambient Temperature\"]=mdf[\"Lower Ambient Temperature\"]\n",
    "    main_df[\"Upper Ambient Temperature\"]=mdf[\"Upper Ambient Temperature\"]\n",
    "    main_df[\"Barometric Pressure\"]=mdf[\"Barometric Pressure\"]\n",
    "    main_df[\"Relative Humidity\"]=mdf[\"RelativeHumidity\"]\n",
    "    main_df[\"Wind Direction\"]=mdf[\"Wind Direction\"]\n",
    "    main_df[\"Wind Speed\"]=mdf[\"Wind Speed\"]\n",
    "    main_df[\"H2S\"]=mdf[\"H2S\"]\n",
    "    main_df[\"Toluene\"]=mdf[\"Toluene\"]\n",
    "    main_df[\"O-Xylene\"]=mdf[\"O_Xylene\"]\n",
    "    main_df[\"Ethylbenzene\"]=mdf[\"EthylBenzene\"]\n",
    "    main_df[\"MP-Xylene\"]=mdf[\"mp_xylene_\"]\n",
    "    main_df[\"Benzene\"]=mdf[\"Benzene\"]\n",
    "    main_df[\"CH4\"]=mdf[\"CH4\"]\n",
    "    main_df[\"NMHC\"]=mdf[\"NMHC\"]\n",
    "    main_df[\"THC\"]=mdf[\"THC\"]\n",
    "    main_df[\"Noise\"]=mdf[\"Noise\"]\n",
    "    \n",
    "    main_df.to_csv(f'/workspaces/vikrant_dubai/Transformed/{excel_file.sheet_names[s]}.csv', index=False)\n",
    "\n",
    "\n",
    "# Get a list of all CSV files in the transformed folder\n",
    "csv_files = [f for f in os.listdir('/workspaces/vikrant_dubai/Transformed') if f.endswith('.csv')]\n",
    "\n",
    "# Read and concatenate all CSV files\n",
    "combined_df = pd.concat([pd.read_csv(os.path.join('/workspaces/vikrant_dubai/Transformed', f)) for f in csv_files], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(f'/workspaces/vikrant_dubai/final/AD {n}.csv', index=False)\n",
    "\n",
    "\n",
    "# Get a list of all files in the Transformed folder\n",
    "files = glob.glob('/workspaces/vikrant_dubai/Transformed/*')\n",
    "\n",
    "# Iterate over the list of files and remove each one\n",
    "for f in files:\n",
    "    os.remove(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
